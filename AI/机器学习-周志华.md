
## ch01-绪论

计算机科学：输入+模型->输出

机器学习：输入+输出->模型

模型：从数据中学习得到的结果
- 模式：模型的一个局部

基本术语：
- *数据集*（data set）：数据记录集合
- *样本*（sample）、*实例*（instance）：数据记录的别称
- *属性*（attribute）、*特征*（feature）：数据记录的某方面表现、性质的反映
	- *属性值*（attribute value）：这一方面的数值
	- *属性空间*（attribute space）、*样本空间*（sample space）：属性张成的空间
- *特征向量*（feature vector）：数据记录的数学表示
- *维度*（dimensionality）：特征向量的维度数
- *学习*（learning）、*训练*（training）：从数据学得模型的过程
- *训练数据*（training data）、*训练样本*（training sample）
- *训练集*（training set）
- *假设*（hypothesis）：学得的模型对应了关于数据的某种潜在规律
	- *真实*（ground-truth）：这种潜在规律自身
	- *学习器*（learner）：模型别称
- *预测*（prediction）
- *标记*（label）、*样例*（example）
- *标记空间*（label space）
- *测试*（testing）：
	- *测试样本*（testing sample）
	- *测试集*（test set）
- 机器学习任务：
	- *分类*（classification）
		- *二分类*（binary classification）：*正类*（positive class）、*反类*（negative class）
		- *多分类*（multi-class classification）
	- *回归*（regression）
	- *聚类*（clustering）：将训练样本分为若干相近的组
		- *簇*（cluster）：每个划分形成的组
- *有监督学习*（supervised learning）：提供标记信息的学习过程
- *无监督学习*（unsupervised learning）：不提供标记信息的学习过程
- *泛化*（generalization）：学得模型适用于新样本的能力
- *分布*（distribution）：样本在样本空间中的分散情况
	- *独立同分布*（independent and identically distributed, i.i.d.）

归纳（induction）：从特殊到一般的泛化过程
- 从具体事实归结出一般规律
- 从样例中学习即是归纳过程
- 广义归纳学习样例特征，狭义归纳学习概念

演绎（deduction）：从一般到特殊的特化过程
- 从一般规律出发推演出具体状况

*归纳偏好*（inductive bias）：如果模型无法确定新样本属于哪个分类，则它必根据自己在学习过程中对某种类型假设的偏好进行归纳。
- 理解：学习算法自身在假设空间中学习成的“价值观”
- 例：模型倾向于认为各种属性均相近的西瓜，成熟程度也相似
- *“没有免费的午餐”定理*（no-free-lunch theorem, NFL）：
	- 各个学习算法在训练集外的期望性能相同，都约等于乱猜
	- 如果一个学习算法$L_a$在训练集上表现比$L_b$好，则必存在另一些数据集使得$L_b$的表现更好
	- 前提：所有问题的出现机会相等，但现实不是这样
	- 启示：谈论哪个学习算法更好时，*必须带上具体问题*

发展历程：
- 1950s-70s: 推理期：
	- Logic Theorist, General Problem Solving, etc.
	- 连接主义学习、感知机、符号主义学习
- 1970s-80s: 知识期
	- 逻辑推理不能实现AI，需要依赖知识
	- 专家系统、知识工程
- 1980s-90s: 机器学习形成
	- Michalski分类：*样例中学习*（广义归纳学习）、问题求解和规划中学习、观察和发现学习、指令中学习
	- 样例学习分支：
		- 符号主义学习：决策树（信息熵最小化）、基于逻辑学习（归纳逻辑程序设计）等
		- 连接主义学习：神经网络、BP算法等
- 1990s-: 统计学习
	- 支持向量机、核方法等
- 2000s-: 连接学习重新兴起
	- 背景：数据量增大，计算能力变强
	- 深度学习：多层神经网络

应用现状：
- 计算机：多媒体/图形学/通信/软工/体系结构/芯片设计
- 交叉学科：生信/CV/etc.
- 数据挖掘：since 90s

## ch02-模型评估与选择

### 2.1-经验误差与过拟合

错误率（error rate）：分类错误的样本数占总样本比例
- 精度（accuracy）：分类正确的样本数占总样本比例
	- 精度=1-错误率
- 误差（error）：实际预测与真实输出的差异
	- 训练误差（training error）、经验误差（empirical error）：在训练集上的误差
	- 泛化误差（generalization error）：在训练集外的误差
- 过拟合（overfitting）：训练样本学得“太好”了，以至于对训练集外的样本表现较差
- 欠拟合（underfitting）：连训练样本都没学好

学习目标：*降低泛化误差*，而非刻意降低训练误差

### 2.2-评估方法

测试集（testing set）：数据集的一个用于评估模型学习效果的子集
- 测试误差（testing error）：模型在测试集上的误差

*训练集-测试集划分手段*：数据集$D$分为训练集$S$，测试集$T$。
- 留出法（hold-out）：$D=S\cup T,S\cap T=\varnothing$。设定$|S|/|T|=k$，一般取$2\sim4$之间。
- 交叉验证法（cross validation）：$D=\bigcup_{i=1}^n D_i$，且$\forall 1\le i,j\le n$，$D_i\cap D_j=\varnothing$。每轮取$T=D_i,S=D-D_i$，总共$n$轮。
- 自助法（bootstrapping）：
	- 每轮随机挑选$x\in D$，将其拷贝入可重集合$S$，总共进行$|D|$轮
	- 当$m$足够大时，任意$x\in D$不在$S$中的概率为$P(x\notin S)=\lim_{m\rightarrow +\infty}(1-1/m)^m=1/e\approx 0.368$ 。
	- 取$T=D-S$，则$T$大约包含36.8%的$D$样本，属合理范围

手段比较：
- 留出法：简单，但偶然性大
- 交叉验证法：偶然性小，但时间成本大
- 自助法：在难于划分数据集时有用，但改变了数据集分布，会引入估计偏差

*调参*（parameter tuning）*与最终模型*：
- 绝大部分模型都有参数，需要调节
- 调参vs算法选择：调参需要试验大量参数，且对模型性能有决定性影响
- 验证集vs测试集：
	- 模型评估&选择时，需要预留一些数据用于验证模型性能，这部分数据称为*验证集*（validation set）
	- 测试集则是确定模型后测试训练效果的数据集

### 2.3-性能度量

模型性能=模型泛化能力

*均方误差*（mean squared error, MSE）：对于模型$f$和数据集$D=\{(x_i,y_i)|1\le i\le m\}$：
$$
E(f;D)=\dfrac{1}{m}\sum_{i=1}^m (f(x_i)-y_i)^2
$$
或更一般地：对于$f$和$D$，设样本$x$在$D$中概率密度$p(\cdot)$，标签为$y$，则：
$$
E(f;D)=\int_{x\sim D} (f(x)-y)^2 p(x)dx
$$

*错误率*（error rate）：设$\mathbb{I}(\cdot)$为单元函数，将布尔表达式映射为$0/1$：
$$
E(f;D)=\int_{x\sim D} \mathbb{I}(f(x)\neq y)\cdot p(x)dx
$$
*精度*（accuracy rate）：
$$
\text{acc}(f;D)=\int_{x\sim D} \mathbb{I}(f(x)= y)\cdot p(x)dx=1-E(f;D)
$$

查准率、查全率、F1：
- 背景：错误率/精度信息不全，可能需要研究误判类型（实际为正预测为反，实际为反预测为正）
- 分类结果：
	- TP/TN：预测、实际均为真/假，true positive/negative
	- FP/FN：预测为真/假，实际为假/真，false positive/negative
- *查准率*（precision）：
	- 概念：TP占所有预测为真样本的比率
	- 定义：$P=\dfrac{TP}{TP+FP}$
- *查全率*（recall）：
	- 概念：TP占所有实际为真样本的比率
	- 定义：$R=\dfrac{TP}{TP+FN}$
- 查准率vs查全率：
	- 两者矛盾，一者偏高则另一者常常偏低：提升查准率需要更保守地预测，但保守预测可能增加FN，从而降低查全率，反之亦然
	- *P-R图*：对所有样本按查全率升序排列，根据当前的实际查准率绘制曲线，形成查准率-查全率曲线
		- 意义：更凸出（或平衡点更高）的曲线表示更优秀的模型
		- 平衡点（break-event point，BEP）：$y=x$与曲线的交点
- F1度量：
	- 意义：查准率和查全率的加权调和平均
	- 一般形式：设查全率对查准率重要度为$\beta$，则$F_\beta=\dfrac{(1+\beta^2)PR}{\beta^2P+R}$。
		- $\beta=1$：*标准F1度量*
		- $\beta>1$表示查全率$R$影响更大，$\beta<1$表示查准率$P$影响更大
- 处理多组混淆矩阵：
	- 计算每组的$(P_i,R_i)$
	- 宏度量：
		- 计算宏查准率和宏查全率：$\text{M-}P=\sum_{i=1}^n P_i/n$，$\text{M-}R=\sum_{i=1}^n R_i/n$。
		- 计算宏F1：$\text{M-}F1=\dfrac{2\times \text{M-}P\times \text{M-}R}{\text{M-}P+\text{M-}R}$。
	- 微度量：
		- 计算每组的TP/FP/TN/FN，并取均值
		- 计算微查准率和微查全率：$\text{m-P}=\dfrac{\overline{TP}}{\overline{TP}+\overline{FP}}$，$\text{m-}R=\dfrac{\overline{TP}}{\overline{TP}+\overline{FN}}$。
		- 计算微F1：$\text{m-}F1=\dfrac{2\times \text{m-}P\times \text{m-}R}{\text{m-}P+\text{m-}R}$。

P-R图示例：

![[Pasted image 20241004172046.png]]

ROC与AUC：
- 背景：在分类任务中，特别是当数据集类别不平衡时，单纯依赖准确率或P-R可能会造成误导
	- 例如：数据集中95%为反例，5%为正例，即使模型总是预测为反例也有95%准确率，但这毫无意义
- 相关指标：
	- 真正例率（true positive rate，TPR）：$TPR=\dfrac{TP}{TP+FN}$。
	- 假正例率（false positive rate，FPR）：$FPR=\dfrac{FP}{TN+FP}$。
- *受试者工作特征*（ROC, receiver operating characteristic）曲线：横轴为样本的假正例率，纵轴为真正例率
	- 绘制过程：假设对每个样本会输出真实率$p_i\in [0,1]$。
		- 取阈值$P\in [0,1]$，对$p_i<P$的样本预测为反例，其余预测为正例，并计算其TPR和FPR。
		- 取足够多的阈值，计算出的TPR/FPR绘制成一条从$(0,0)$到$(1,1)$的曲线
- 曲线下面积（AUC, area under the curve）：ROC曲线下面积，又称AUC，可用于衡量一个学习器的效果
	- 计算方式：设阈值TPR-FPR为$\{(x_i,y_i)\}$，则$\text{AUC}=\dfrac{1}{2}\displaystyle\sum_{i=1}^{m-1} (x_{i+1}-x_i)\cdot (y_i+y_{i+1})$。
	- 衡量方式：AUC>0.5说明有一定学习效果，AUC=0.5说明和瞎猜没区别，AUC<0.5说明还不如瞎猜

![[Pasted image 20241005194225.png]]

代价敏感错误率、代价曲线：
- 背景：两类错误的代价有时不同：如果实际正常被误诊为患病，影响有限；实际患病被误诊为正常，则可能产生严重后果。因此两类错误可能需要指定*非均等代价*（unequal cost）
- 非均等代价：设置$k$分类代价矩阵$\{cost_{ij}\}$（$i,j\in \{0,1,\ldots,k-1\}$），对所有的$i\neq j$设置$cost_{ij}>0$。
- 代价敏感错误率（cost-sensitive error rate）：设判为反例的样例集为$D^-$，判为正例的样例集为$D^+$，则：
	- $E(f;D;cost)=\dfrac{1}{m}\left(\sum_{x_i\in D^+} \mathbb{I}(f(x_i)\neq y_i)\cdot cost_{01}+\sum_{x_i\in D^-} \mathbb{I}(f(x_i)\neq y_i)\cdot cost_{10}\right)$
- *代价曲线*（cost curve）：反映学习器的真实损失情况