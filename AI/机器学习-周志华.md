
## ch01-绪论

计算机科学：输入+模型->输出

机器学习：输入+输出->模型

模型：从数据中学习得到的结果
- 模式：模型的一个局部

基本术语：
- *数据集*（data set）：数据记录集合
- *样本*（sample）、*实例*（instance）：数据记录的别称
- *属性*（attribute）、*特征*（feature）：数据记录的某方面表现、性质的反映
	- *属性值*（attribute value）：这一方面的数值
	- *属性空间*（attribute space）、*样本空间*（sample space）：属性张成的空间
- *特征向量*（feature vector）：数据记录的数学表示
- *维度*（dimensionality）：特征向量的维度数
- *学习*（learning）、*训练*（training）：从数据学得模型的过程
- *训练数据*（training data）、*训练样本*（training sample）
- *训练集*（training set）
- *假设*（hypothesis）：学得的模型对应了关于数据的某种潜在规律
	- *真实*（ground-truth）：这种潜在规律自身
	- *学习器*（learner）：模型别称
- *预测*（prediction）
- *标记*（label）、*样例*（example）
- *标记空间*（label space）
- *测试*（testing）：
	- *测试样本*（testing sample）
	- *测试集*（test set）
- 机器学习任务：
	- *分类*（classification）
		- *二分类*（binary classification）：*正类*（positive class）、*反类*（negative class）
		- *多分类*（multi-class classification）
	- *回归*（regression）
	- *聚类*（clustering）：将训练样本分为若干相近的组
		- *簇*（cluster）：每个划分形成的组
- *有监督学习*（supervised learning）：提供标记信息的学习过程
- *无监督学习*（unsupervised learning）：不提供标记信息的学习过程
- *泛化*（generalization）：学得模型适用于新样本的能力
- *分布*（distribution）：样本在样本空间中的分散情况
	- *独立同分布*（independent and identically distributed, i.i.d.）

归纳（induction）：从特殊到一般的泛化过程
- 从具体事实归结出一般规律
- 从样例中学习即是归纳过程
- 广义归纳学习样例特征，狭义归纳学习概念

演绎（deduction）：从一般到特殊的特化过程
- 从一般规律出发推演出具体状况

*归纳偏好*（inductive bias）：如果模型无法确定新样本属于哪个分类，则它必根据自己在学习过程中对某种类型假设的偏好进行归纳。
- 理解：学习算法自身在假设空间中学习成的“价值观”
- 例：模型倾向于认为各种属性均相近的西瓜，成熟程度也相似
- *“没有免费的午餐”定理*（no-free-lunch theorem, NFL）：
	- 各个学习算法在训练集外的期望性能相同，都约等于乱猜
	- 如果一个学习算法$L_a$在训练集上表现比$L_b$好，则必存在另一些数据集使得$L_b$的表现更好
	- 前提：所有问题的出现机会相等，但现实不是这样
	- 启示：谈论哪个学习算法更好时，*必须带上具体问题*

发展历程：
- 1950s-70s: 推理期：
	- Logic Theorist, General Problem Solving, etc.
	- 连接主义学习、感知机、符号主义学习
- 1970s-80s: 知识期
	- 逻辑推理不能实现AI，需要依赖知识
	- 专家系统、知识工程
- 1980s-90s: 机器学习形成
	- Michalski分类：*样例中学习*（广义归纳学习）、问题求解和规划中学习、观察和发现学习、指令中学习
	- 样例学习分支：
		- 符号主义学习：决策树（信息熵最小化）、基于逻辑学习（归纳逻辑程序设计）等
		- 连接主义学习：神经网络、BP算法等
- 1990s-: 统计学习
	- 支持向量机、核方法等
- 2000s-: 连接学习重新兴起
	- 背景：数据量增大，计算能力变强
	- 深度学习：多层神经网络

应用现状：
- 计算机：多媒体/图形学/通信/软工/体系结构/芯片设计
- 交叉学科：生信/CV/etc.
- 数据挖掘：since 90s

## ch02-模型评估与选择

### 2.1-经验误差与过拟合

错误率（error rate）：分类错误的样本数占总样本比例
- 精度（accuracy）：分类正确的样本数占总样本比例
	- 精度=1-错误率
- 误差（error）：实际预测与真实输出的差异
	- 训练误差（training error）、经验误差（empirical error）：在训练集上的误差
	- 泛化误差（generalization error）：在训练集外的误差
- 过拟合（overfitting）：训练样本学得“太好”了，以至于对训练集外的样本表现较差
- 欠拟合（underfitting）：连训练样本都没学好
- 