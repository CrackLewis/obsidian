
Chinchilla: “别nm瞎堆参数了”

*核心结论*：对于给定的算力预算，模型参数量和训练数据量应该等比例增加。最佳比例大概是 20 个 Token 对应 1 个参数。

refs:
- [zhihu1](https://zhuanlan.zhihu.com/p/1922062257493373239)
- [arxiv-预训练scaling](https://arxiv.org/abs/2203.15556)

## 三大定律

*预训练scaling*：通过扩大训练数据集规模、增加模型参数数量和计算资源，可以实现模型性能的提升

*后训练scaling*：后训练技术能够进一步提升模型针对特定应用的适应性与相关性
- 预训练：“学校念书”，后训练：“职场培训”
- 通过微调、剪枝、量化、蒸馏、强化学习和合成数据增强等技术，可以进一步提升预训练模型的计算效率、准确率或领域适应性
	- 微调：使用额外训练数据，将AI模型调整到特定领域或应用。可采用公司内部数据集，或输入/输出样例对
	- 蒸馏：采用一对AI模型：一个复杂“教师”模型与一个轻量“学生”模型。最常见的是离线蒸馏，学生模型学习模仿教师模型的输出
	- 强化学习：基于奖励机制训练大模型，使其在特定任务中做出最优决策。例如：RLHF、RLAIF
	- Best-of-n采样：生成多个模型输出，选择根据奖励模型评分最高的结果。无需修改模型参数，即可提升输出质量，是微调与强化学习的替代方案
	- 搜索方法：探索各种潜在决策路径后再选择最终输出，可反复改进模型回答

*推理scaling*（长思考，long thinking）：
- 当模型需要解决复杂问题时，常需要进行多步推理
- 强调通过动态调整奖励机制来提升模型的推理能力，而非传统的通过增加模型参数或训练数据
- 