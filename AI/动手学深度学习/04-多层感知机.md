
多层感知机是最简单的深度神经网络。

核心问题：
- 网络结构：隐藏层、激活函数
- 过拟合、欠拟合、模型选择
- 正则化技术：权重衰减、暂退法等
- 数值稳定性、参数初始化

## 简介

线性模型的弊端：输出和输入不一定是单调线性关系。

解决方案：在网络中引入一或多个隐藏层。隐藏层在输入层和输出层之间，引入隐藏层可以克服线性模型的限制，从而使网络能够处理更复杂的函数关系类型。

![[Pasted image 20240829104418.png]]

具有1个输入层、1个输出层和至少一个隐藏层的神经网络称为*多层感知机*（multi-layer perceptron，MLP）。这种网络可以在一定的输入范围内，拟合非线性的函数关系。

对于单个隐藏层的MLP，假设：
- 批次大小为$n$，输入维度为$d$，模型输入为$X_{n\times d}$；
- 隐藏层特征数为$h$，隐藏层输出为$H_{n\times h}$；
- 输出维度为$q$，模型输出为$O_{n\times q}$。

则对于隐藏层输出$H$，有：
$$
H_{n\times h} = X_{n\times d} \cdot W_{d\times h}^{(1)}+b_{n\times h}^{(1)}
$$
对于模型输出$O$，有：
$$
O_{n\times q}=H_{n\times h}\cdot W_{h\times q}^{(2)}+b_{n\times q}^{(2)}
$$
基于上述两步的方程是：
$$
\begin{split}
O&=XW+b \\
W&=W^{(1)}W^{(2)} \\
b&=b^{(1)}W^{(2)}+b^{(2)}
\end{split}
$$

进一步，为发挥多层架构潜力，引入*激活函数*（activation function），将其应用于隐藏层输出中。激活函数输出称为*活性值*（activations）：
$$
\begin{split}
H&=\sigma(XW^{(1)}+b^{(1)}) \\
O&=HW^{(2)}+b^{(2)}
\end{split}
$$
注意：
- 激活函数$\sigma(\cdot)$单次只计算一行。
- 应用了激活函数的模型不可能退化回线性模型。
- 激活函数可以应用到每个隐藏层，而不必是单个；每层的激活函数可以不同。

## 激活函数

最常用的有ReLU、sigmoid、tanh。

*ReLU函数*：又称修正线性单元（rectified linear unit，ReLU）函数，它是元素和0取最大值：
$$
\text{ReLU}(x)=\max(x,0)
$$
该函数最受欢迎，实现简单，表现也较良好。它的导数非0即1，要么让参数消失，要么通过，可以解决梯度消失问题。

有一种称为参数化ReLU（parameterized ReLU，pReLU）的变体，允许部分负面参数通过：
$$
\text{pReLU}(x)=\max(x,0)+\alpha \min(x,0)
$$
绘制函数：

```python
x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)
y = torch.relu(x)
d2l.plot(x.detach(), y.detach(), 'x', 'relu(x)', figsize=(5, 2.5))
```

![[Pasted image 20240829165724.png]]

*sigmoid函数*：又称挤压函数，它可以将参数挤压至$(0,1)$区间：
$$
\text{sigmoid}(x)=\dfrac{1}{1+\exp(-x)}
$$
它的导数满足：
$$
\dfrac{d}{dx}\text{sigmoid}(x)=\dfrac{\exp(-x)}{(1+\exp(-x))^2}=\text{sigmoid}(x)\cdot (1-\text{sigmoid}(x))
$$
绘制函数：
```python
x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)
y = torch.sigmoid(x)
d2l.plot(x.detach(), y.detach(), 'x', 'sigmoid(x)', figsize=(5, 2.5))
```

![[Pasted image 20240829165925.png]]

*tanh函数*：双曲正切函数。与sigmoid类似，它也压缩实数区间，但是压到$(-1,1)$区间：
$$
\tanh(x)=\dfrac{1-\exp(-2x)}{1+\exp(-2x)}
$$
其导数满足：
$$
\dfrac{d}{dx}\tanh(x)=1-\tanh^2(x)
$$
绘制函数：
```python
x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)
y = torch.tanh(x)
d2l.plot(x.detach(), y.detach(), 'x', 'tanh(x)', figsize=(5, 2.5))
```

![[Pasted image 20240829170319.png]]

## 多层感知机实现

MLP的实现仍然是基于Fashion-MNIST的图片分类模型。

### 数据集、模型参数

导入包、读取数据集、设置批次大小：

```python
import torch
from torch import nn
from d2l import torch as d2l

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
```

输入参数为784个，输出参数为10个。将隐藏层参数设置为256个，并赋予初值：

```python
num_inputs, num_outputs, num_hiddens = 784, 10, 256

W1 = nn.Parameter(torch.randn(
    num_inputs, num_hiddens, requires_grad=True) * 0.01)
b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))
W2 = nn.Parameter(torch.randn(
    num_hiddens, num_outputs, requires_grad=True) * 0.01)
b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))

params = [W1, b1, W2, b2]
```

### 模型

激活函数采用ReLU：

```python
def relu(X):
    a = torch.zeros_like(X)
    return torch.max(X, a)
```

损失函数采用交叉熵损失：

```python
loss = nn.CrossEntropyLoss(reduction='none')
```

模型采用隐藏层，所以需要声明一个张量存储隐藏层的运算结果：

```python
def net(X):
    X = X.reshape((-1, num_inputs))
    H = relu(X@W1 + b1)  # 这里“@”代表矩阵乘法
    return (H@W2 + b2)
```

### 训练和评估

```python
num_epochs, lr = 10, 0.1
updater = torch.optim.SGD(params, lr=lr)
train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)

predict_ch3(net, test_iter)
```

### 基于PyTorch的改进

PyTorch以一种声明式的方式组建网络模型。`torch.nn.Sequential`将多个网络层串联起来，`torch.nn.Flatten`是扁平化层，`nn.Linear(in_feats, out_feats)`是全连接层，`nn.ReLU`则是ReLU套壳。

组建图片分类模型可以通过下列源码简单实现：

```python
# 声明网络模型为net
net = nn.Sequential(nn.Flatten(),
                    nn.Linear(784, 256),
                    nn.ReLU(),
                    nn.Linear(256, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

# 将init_weights函数递归地作用于网络模型内的所有
net.apply(init_weights)
```

其余的部分改动不大。

## 模型选择、欠拟合、过拟合

背景：模型需要真正发现泛化的模式，而非简单地记忆数据。对部分数据的过度学习可能导致对其他数据处理效果变差。

*过拟合*（overfitting）：模型在训练数据上拟合的比在潜在分布中更接近（在测试数据中表现较差）。对抗过拟合的技术称为*正则化*（regularization）。

### 训练误差、泛化误差

*训练误差*（training error）：模型在训练数据集上得到的误差。

*泛化误差*（generalization error）：模型应用在同样从原始样本中的分布中抽取的无限多数据样本时，模型误差的期望。
- 准确计算泛化误差不可能，只能由测试集误差近似评估。

训练集和测试集应尽可能满足独立同分布假设，即出自同一个数据分布。

模型复杂性：参数个数、参数取值范围大小、训练迭代次数。

*一条经验法则*：能够轻松解释任意事实的模型是复杂的， 而表达能力有限但仍能很好地解释数据的模型可能更有现实用途。

影响模型泛化的因素：
- 可调整参数的数量（自由度）
- 参数采用的值
- 训练样本的数量

### 欠拟合、过拟合

| 情形    | 训练误差小 | 训练误差大 |
| ----- | ----- | ----- |
| 验证误差小 | 好好好   | 见鬼了   |
| 验证误差大 | *过拟合* | *欠拟合* |

发生欠拟合或过拟合的诱因：
- 模型过于复杂或过于简单
- 数据集太少
- 数据取值过于宽泛

### 例：多项式回归（WIP）

[link](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html#id11)

## 权重衰减

这篇博客写的比d2l官方要好：[blog](https://blog.csdn.net/zhaohongfei_358/article/details/129625803)

*权重衰减*（weight decay）是训练参数化模型中使用的一种正则化技术，又称L2正则化。这项技术通过测量函数和零的距离，衡量函数的复杂度，作用是*抑制模型的过拟合*。

*思想*：给损失函数增加模型权重的L2范数作为惩罚（penalty），从而鼓励模型通过减小模型权重来减小总损失。

核心问题：
- 什么是正则化？
- Weight Decay的减少模型参数的思想
- L1范数惩罚项和L2范数惩罚项分别是什么？
- 为什么Weight Decay参数应用在优化器，而非损失函数？
- 调参技巧

### 正则化思想

*正则化*（regularization）是对参数进行规范化，目的是将参数控制在可控范围，以减小方差和减少数据扰动的影响。
- 数据扰动：数据集内数据本身不可避免的差异
- 方差：刻画数据扰动造成的影响
- 偏差：刻画学习算法本身的拟合能力。有时偏差和噪声会合称偏差
- 噪声：当前任务任何学习算法能达到的期望泛化误差的下界

![](https://i-blog.csdnimg.cn/blog_migrate/e333a15314e11e30d494f62af3919f96.png)

- 上图红线=测试集误差=方差+偏差+噪声
- 上图黄线=训练集误差=偏差+噪声

### 减小模型权重思想

同样的模型，参数值（的绝对值）越小，模型越简单，比如下面这个多项式回归模型：

![](https://i-blog.csdnimg.cn/blog_migrate/476f14415ebf955fd1923cca5023b496.png)

### 为损失函数增加惩罚项

设模型权重为$w$，损失函数为$L_0(w)$，正常情况下模型需要寻求一个最合适的$w$，最小化损失函数：
$$
w=\operatorname*{argmin}_{w} L_0(w)
$$

考虑构建新损失函数$L(w)$，在$L_0$的基础上添加模型权重的L2范数，新添加的项称为*惩罚项*（penalty），会在模型权重过大时显著增加损失：
$$
L(w)=L_0(w)+\dfrac{\lambda}{2}||w||^2
$$
其中$\lambda$是一个控制权重衰减强度的超参数。在权重，模型不再最小化$L_0(w)$，而是最小化$L(w)$，以使$L_0$和权重大小综合最小：
$$
w=\operatorname*{argmin}_{w} L_0(w)+\dfrac{\lambda}{2}||w||^2
$$


不难看出：
- 模型权重或$\lambda$越大，$L$越大。
- $\lambda$过小会使权重衰减效果不明显；$\lambda$过大会过度增大惩罚，使得模型专注于降低权重，从而忽略了$L_0$的最小化。

*为什么不用L1范数*作为惩罚项：L1范数是各权重的绝对值之和，它倾向于让部分权重归零，而这显然不是正则化的目标。

### 实现权重衰减

在一般的梯度下降过程中，梯度的下降程度与学习率$\gamma$和梯度成正比：
$$
w\leftarrow w-\gamma \dfrac{\partial L_0(w)}{\partial w}
$$
用前面的$L(w)$代换$L_0(w)$，得到：
$$
\begin{split}
w &\leftarrow w-\gamma \dfrac{\partial \left(L_0(w)+\dfrac{\lambda}{2}||w||^2\right)}{\partial w} \\
&\leftarrow w-\gamma \left(\dfrac{\partial L_0(w)}{\partial w}+\lambda w\right) \\
&\leftarrow (1-\gamma\lambda)w-\gamma \dfrac{\partial L_0(w)}{\partial w}
\end{split}
$$
在PyTorch中，可以在优化器创建时指定`weight_decay`参数，例如`torch.optim.SGD`便支持设置这一参数：

![](https://i-blog.csdnimg.cn/blog_migrate/2a6205fffcb54a838dd06c7320d1728e.png)

手动实现：

```python
# 初始化模型权重和偏移
def init_params():
    w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True)
    b = torch.zeros(1, requires_grad=True)
    return [w, b]

# 计算惩罚值，即权重的L2范数
def l2_penalty(w):
    return torch.sum(w.pow(2)) / 2

def train(lambd):
    w, b = init_params()
    # 模型采取线性回归模型
    net = lambda X: d2l.linreg(X, w, b)
    # 损失函数采取均方损失
    loss = d2l.squared_loss
    # 超参数
    num_epochs, lr = 100, 0.003
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',
                            xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            # 增加了L2范数惩罚项，
            # 广播机制使l2_penalty(w)成为一个长度为batch_size的向量
            l = loss(net(X), y) + lambd * l2_penalty(w)
            l.sum().backward()
            d2l.sgd([w, b], lr, batch_size)
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss),
                                     d2l.evaluate_loss(net, test_iter, loss)))
    print('w的L2范数是：', torch.norm(w).item())

train(lambd=3)
```

或如下的简化实现版本：

```python
def train_concise(wd):
    net = nn.Sequential(nn.Linear(num_inputs, 1))
    for param in net.parameters():
        param.data.normal_()
    loss = nn.MSELoss(reduction='none')
    num_epochs, lr = 100, 0.003
    # 偏置参数没有衰减
    trainer = torch.optim.SGD([
        {"params":net[0].weight,'weight_decay': wd},
        {"params":net[0].bias}], lr=lr)
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',
                            xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            trainer.zero_grad()
            l = loss(net(X), y)
            l.mean().backward()
            trainer.step()
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1,
                         (d2l.evaluate_loss(net, train_iter, loss),
                          d2l.evaluate_loss(net, test_iter, loss)))
    print('w的L2范数：', net[0].weight.norm().item())

train_concise(wd=3)
```

### 技巧

- 权重衰减优化作用有限，尤其是在模型极其复杂时，效果只有一点点。
- 权重系数一般取`1e-3`左右，在`[1e-4,1e-2]`区间内。
- 一般不对偏移值作权重衰减，因为没啥效果，调整大了还容易过拟合。

## 暂退法（dropout）

回顾过拟合的3个常见诱因：
- 权重值的范围太大，导致模型极其不稳定（权重衰减）
- 对于简单的数据选取的模型过于复杂，比如隐藏层过多，隐藏层的神经元过多
- 训练样本过少，导致模型对少样本完全拟合，对于新样本极其陌生（改进数据集）

对于情形2，解决方案一般是调整活动的模型参数个数。但直接调整模型大小过于繁琐，所以引入*暂退法*（drop-out method），这种方法可以方便我们调整模型复杂度，可以减少隐藏神经元个数，同时对整个神经网络不产生影响。

![](https://i-blog.csdnimg.cn/blog_migrate/c075a55296d2581f2aa7b8135688c166.png)

