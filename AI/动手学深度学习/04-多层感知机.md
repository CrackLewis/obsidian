
多层感知机是最简单的深度神经网络。

核心问题：
- 网络结构：隐藏层、激活函数
- 过拟合、欠拟合、模型选择
- 正则化技术：权重衰减、暂退法等
- 数值稳定性、参数初始化

## 简介

线性模型的弊端：输出和输入不一定是单调线性关系。

解决方案：在网络中引入一或多个隐藏层。隐藏层在输入层和输出层之间，引入隐藏层可以克服线性模型的限制，从而使网络能够处理更复杂的函数关系类型。

![[Pasted image 20240829104418.png]]

具有1个输入层、1个输出层和至少一个隐藏层的神经网络称为*多层感知机*（multi-layer perceptron，MLP）。这种网络可以在一定的输入范围内，拟合非线性的函数关系。

对于单个隐藏层的MLP，假设：
- 批次大小为$n$，输入维度为$d$，模型输入为$X_{n\times d}$；
- 隐藏层特征数为$h$，隐藏层输出为$H_{n\times h}$；
- 输出维度为$q$，模型输出为$O_{n\times q}$。

则对于隐藏层输出$H$，有：
$$
H_{n\times h} = X_{n\times d} \cdot W_{d\times h}^{(1)}+b_{n\times h}^{(1)}
$$
对于模型输出$O$，有：
$$
O_{n\times q}=H_{n\times h}\cdot W_{h\times q}^{(2)}+b_{n\times q}^{(2)}
$$
基于上述两步的方程是：
$$
\begin{split}
O&=XW+b \\
W&=W^{(1)}W^{(2)} \\
b&=b^{(1)}W^{(2)}+b^{(2)}
\end{split}
$$

进一步，为发挥多层架构潜力，引入*激活函数*（activation function），将其应用于隐藏层输出中。激活函数输出称为*活性值*（activations）：
$$
\begin{split}
H&=\sigma(XW^{(1)}+b^{(1)}) \\
O&=HW^{(2)}+b^{(2)}
\end{split}
$$
注意：
- 激活函数$\sigma(\cdot)$单次只计算一行。
- 应用了激活函数的模型不可能退化回线性模型。
- 激活函数可以应用到每个隐藏层，而不必是单个；每层的激活函数可以不同。

## 激活函数

最常用的有ReLU、sigmoid、tanh。

*ReLU函数*：又称修正线性单元（rectified linear unit，ReLU）函数，它是元素和0取最大值：
$$
\text{ReLU}(x)=\max(x,0)
$$
该函数最受欢迎，实现简单，表现也较良好。它的导数非0即1，要么让参数消失，要么通过，可以解决梯度消失问题。

有一种称为参数化ReLU（parameterized ReLU，pReLU）的变体，允许部分负面参数通过：
$$
\text{pReLU}(x)=\max(x,0)+\alpha \min(x,0)
$$
绘制函数：

```python
x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)
y = torch.relu(x)
d2l.plot(x.detach(), y.detach(), 'x', 'relu(x)', figsize=(5, 2.5))
```

![[Pasted image 20240829165724.png]]

*sigmoid函数*：又称挤压函数，它可以将参数挤压至$(0,1)$区间：
$$
\text{sigmoid}(x)=\dfrac{1}{1+\exp(-x)}
$$
它的导数满足：
$$
\dfrac{d}{dx}\text{sigmoid}(x)=\dfrac{\exp(-x)}{(1+\exp(-x))^2}=\text{sigmoid}(x)\cdot (1-\text{sigmoid}(x))
$$
绘制函数：
```python
x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)
y = torch.sigmoid(x)
d2l.plot(x.detach(), y.detach(), 'x', 'sigmoid(x)', figsize=(5, 2.5))
```

![[Pasted image 20240829165925.png]]

*tanh函数*：双曲正切函数。与sigmoid类似，它也压缩实数区间，但是压到$(-1,1)$区间：
$$
\tanh(x)=\dfrac{1-\exp(-2x)}{1+\exp(-2x)}
$$
其导数满足：
$$
\dfrac{d}{dx}\tanh(x)=1-\tanh^2(x)
$$
绘制函数：
```python
x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)
y = torch.tanh(x)
d2l.plot(x.detach(), y.detach(), 'x', 'tanh(x)', figsize=(5, 2.5))
```

![[Pasted image 20240829170319.png]]

## 多层感知机实现

MLP的实现仍然是基于Fashion-MNIST的图片分类模型。

### 数据集、模型参数

导入包、读取数据集、设置批次大小：

```python
import torch
from torch import nn
from d2l import torch as d2l

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
```

输入参数为784个，输出参数为10个。将隐藏层参数设置为256个，并赋予初值：

```python
num_inputs, num_outputs, num_hiddens = 784, 10, 256

W1 = nn.Parameter(torch.randn(
    num_inputs, num_hiddens, requires_grad=True) * 0.01)
b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))
W2 = nn.Parameter(torch.randn(
    num_hiddens, num_outputs, requires_grad=True) * 0.01)
b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))

params = [W1, b1, W2, b2]
```

### 模型

激活函数采用ReLU：

```python
def relu(X):
    a = torch.zeros_like(X)
    return torch.max(X, a)
```

损失函数采用交叉熵损失：

```python
loss = nn.CrossEntropyLoss(reduction='none')
```

模型采用隐藏层，所以需要声明一个张量存储隐藏层的运算结果：

```python
def net(X):
    X = X.reshape((-1, num_inputs))
    H = relu(X@W1 + b1)  # 这里“@”代表矩阵乘法
    return (H@W2 + b2)
```

### 训练和评估

```python
num_epochs, lr = 10, 0.1
updater = torch.optim.SGD(params, lr=lr)
train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)

predict_ch3(net, test_iter)
```

### 基于PyTorch的改进

PyTorch以一种声明式的方式组建网络模型。`torch.nn.Sequential`将多个网络层串联起来，`torch.nn.Flatten`是扁平化层，`nn.Linear(in_feats, out_feats)`是全连接层，`nn.ReLU`则是ReLU套壳。

组建图片分类模型可以通过下列源码简单实现：

```python
# 声明网络模型为net
net = nn.Sequential(nn.Flatten(),
                    nn.Linear(784, 256),
                    nn.ReLU(),
                    nn.Linear(256, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

# 将init_weights函数递归地作用于网络模型内的所有
net.apply(init_weights)
```

其余的部分改动不大。

## 模型选择、欠拟合、过拟合

背景：模型需要真正发现泛化的模式，而非简单地记忆数据。对部分数据的过度学习可能导致对其他数据处理效果变差。

*过拟合*（overfitting）：模型在训练数据上拟合的比在潜在分布中更接近（在测试数据中表现较差）。对抗过拟合的技术称为*正则化*（regularization）。

### 训练误差、泛化误差

*训练误差*（training error）：模型在训练数据集上得到的误差。

*泛化误差*（generalization error）：模型应用在同样从原始样本中的分布中抽取的无限多数据样本时，模型误差的期望。
- 准确计算泛化误差不可能，只能由测试集误差近似评估。

训练集和测试集应尽可能满足独立同分布假设，即出自同一个数据分布。

模型复杂性：参数个数、参数取值范围大小、训练迭代次数。

*一条经验法则*：能够轻松解释任意事实的模型是复杂的， 而表达能力有限但仍能很好地解释数据的模型可能更有现实用途。

影响模型泛化的因素：
- 可调整参数的数量（自由度）
- 参数采用的值
- 训练样本的数量

### 欠拟合、过拟合

| 情形    | 训练误差小 | 训练误差大 |
| ----- | ----- | ----- |
| 验证误差小 | 好好好   | 见鬼了   |
| 验证误差大 | *过拟合* | *欠拟合* |

发生欠拟合或过拟合的诱因：
- 模型过于复杂或过于简单
- 数据集太少
- 数据取值过于宽泛

### 例：多项式回归（WIP）

[link](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html#id11)

## 权重衰减

这篇博客写的比d2l官方要好：[blog](https://blog.csdn.net/zhaohongfei_358/article/details/129625803)

*权重衰减*（weight decay）是训练参数化模型中使用的一种正则化技术，又称L2正则化。这项技术通过测量函数和零的距离，衡量函数的复杂度，作用是*抑制模型的过拟合*。

*思想*：给损失函数增加模型权重的L2范数作为惩罚（penalty），从而鼓励模型通过减小模型权重来减小总损失。

核心问题：
- 什么是正则化？
- Weight Decay的减少模型参数的思想
- L1范数惩罚项和L2范数惩罚项分别是什么？
- 为什么Weight Decay参数应用在优化器，而非损失函数？
- 调参技巧

### 正则化思想

*正则化*（regularization）是对参数进行规范化，目的是将参数控制在可控范围，以减小方差和减少数据扰动的影响。
- 数据扰动：数据集内数据本身不可避免的差异
- 方差：刻画数据扰动造成的影响
- 偏差：刻画学习算法本身的拟合能力。有时偏差和噪声会合称偏差
- 噪声：当前任务任何学习算法能达到的期望泛化误差的下界

![](https://i-blog.csdnimg.cn/blog_migrate/e333a15314e11e30d494f62af3919f96.png)

- 上图红线=测试集误差=方差+偏差+噪声
- 上图黄线=训练集误差=偏差+噪声

### 减小模型权重思想

同样的模型，参数值（的绝对值）越小，模型越简单，比如下面这个多项式回归模型：

![](https://i-blog.csdnimg.cn/blog_migrate/476f14415ebf955fd1923cca5023b496.png)

### 为损失函数增加惩罚项

设模型权重为$w$，损失函数为$L_0(w)$，正常情况下模型需要寻求一个最合适的$w$，最小化损失函数：
$$
w=\operatorname*{argmin}_{w} L_0(w)
$$

考虑构建新损失函数$L(w)$，在$L_0$的基础上添加模型权重的L2范数，新添加的项称为*惩罚项*（penalty），会在模型权重过大时显著增加损失：
$$
L(w)=L_0(w)+\dfrac{\lambda}{2}||w||^2
$$
其中$\lambda$是一个控制权重衰减强度的超参数。在权重，模型不再最小化$L_0(w)$，而是最小化$L(w)$，以使$L_0$和权重大小综合最小：
$$
w=\operatorname*{argmin}_{w} L_0(w)+\dfrac{\lambda}{2}||w||^2
$$


不难看出：
- 模型权重或$\lambda$越大，$L$越大。
- $\lambda$过小会使权重衰减效果不明显；$\lambda$过大会过度增大惩罚，使得模型专注于降低权重，从而忽略了$L_0$的最小化。

*为什么不用L1范数*作为惩罚项：L1范数是各权重的绝对值之和，它倾向于让部分权重归零，而这显然不是正则化的目标。

### 实现权重衰减

在一般的梯度下降过程中，梯度的下降程度与学习率$\gamma$和梯度成正比：
$$
w\leftarrow w-\gamma \dfrac{\partial L_0(w)}{\partial w}
$$
用前面的$L(w)$代换$L_0(w)$，得到：
$$
\begin{split}
w &\leftarrow w-\gamma \dfrac{\partial \left(L_0(w)+\dfrac{\lambda}{2}||w||^2\right)}{\partial w} \\
&\leftarrow w-\gamma \left(\dfrac{\partial L_0(w)}{\partial w}+\lambda w\right) \\
&\leftarrow (1-\gamma\lambda)w-\gamma \dfrac{\partial L_0(w)}{\partial w}
\end{split}
$$
在PyTorch中，可以在优化器创建时指定`weight_decay`参数，例如`torch.optim.SGD`便支持设置这一参数：

![](https://i-blog.csdnimg.cn/blog_migrate/2a6205fffcb54a838dd06c7320d1728e.png)

手动实现：

```python
# 初始化模型权重和偏移
def init_params():
    w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True)
    b = torch.zeros(1, requires_grad=True)
    return [w, b]

# 计算惩罚值，即权重的L2范数
def l2_penalty(w):
    return torch.sum(w.pow(2)) / 2

def train(lambd):
    w, b = init_params()
    # 模型采取线性回归模型
    net = lambda X: d2l.linreg(X, w, b)
    # 损失函数采取均方损失
    loss = d2l.squared_loss
    # 超参数
    num_epochs, lr = 100, 0.003
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',
                            xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            # 增加了L2范数惩罚项，
            # 广播机制使l2_penalty(w)成为一个长度为batch_size的向量
            l = loss(net(X), y) + lambd * l2_penalty(w)
            l.sum().backward()
            d2l.sgd([w, b], lr, batch_size)
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss),
                                     d2l.evaluate_loss(net, test_iter, loss)))
    print('w的L2范数是：', torch.norm(w).item())

train(lambd=3)
```

或如下的简化实现版本：

```python
def train_concise(wd):
    net = nn.Sequential(nn.Linear(num_inputs, 1))
    for param in net.parameters():
        param.data.normal_()
    loss = nn.MSELoss(reduction='none')
    num_epochs, lr = 100, 0.003
    # 偏置参数没有衰减
    trainer = torch.optim.SGD([
        {"params":net[0].weight,'weight_decay': wd},
        {"params":net[0].bias}], lr=lr)
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',
                            xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            trainer.zero_grad()
            l = loss(net(X), y)
            l.mean().backward()
            trainer.step()
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1,
                         (d2l.evaluate_loss(net, train_iter, loss),
                          d2l.evaluate_loss(net, test_iter, loss)))
    print('w的L2范数：', net[0].weight.norm().item())

train_concise(wd=3)
```

### 技巧

- 权重衰减优化作用有限，尤其是在模型极其复杂时，效果只有一点点。
- 权重系数一般取`1e-3`左右，在`[1e-4,1e-2]`区间内。
- 一般不对偏移值作权重衰减，因为没啥效果，调整大了还容易过拟合。

## 暂退法（dropout）

回顾过拟合的3个常见诱因：
- 权重值的范围太大，导致模型极其不稳定（权重衰减）
- 对于简单的数据选取的模型过于复杂，比如隐藏层过多，隐藏层的神经元过多
- 训练样本过少，导致模型对少样本完全拟合，对于新样本极其陌生（改进数据集）

对于情形2，解决方案一般是调整活动的模型参数个数。但直接调整模型大小过于繁琐，所以引入*暂退法*（drop-out method），这种方法可以方便我们调整模型复杂度，可以减少隐藏神经元个数，同时对整个神经网络不产生影响。

![](https://i-blog.csdnimg.cn/blog_migrate/c075a55296d2581f2aa7b8135688c166.png)

*暂退法*的思想是：在模型计算过程中，取消隐藏层部分结点的输出，从而减少隐藏层的参数数量。这样可以适当简化模型。

假设隐藏层结点个数为$m$，输出为$h_i$（$1\le i\le m$），取消的结点比例为$p$。则实际输出$h'$为：
$$
h_i'=\left\{
\begin{matrix}
0, & P=p, \\
\dfrac{h_i}{1-p}, & \text{otherwise}.
\end{matrix}
\right.
$$
这样有效参数期望为$m(1-p)$，而隐藏层参数总和的期望不变：
$$
E(h')=\sum E(h_i') = (1-p)\sum  \dfrac{E(h_i)}{1-p}=\sum E(h_i)=E(h)
$$

### 实现dropout

实现一个dropout层：

```python
import torch
from torch import nn
from d2l import torch as d2l

def dropout_layer(X, dropout):
	# dropout指的就是多少概率的神经元被删
	# 因此概率必须在0-1，不在这范围就报错
    assert 0 <= dropout <= 1
    # 在本情况中，所有元素都被丢弃
    if dropout == 1:
        return torch.zeros_like(X)
    # 在本情况中，所有元素都被保留
    if dropout == 0:
        return X
    # 随机出X.shape长度的随机数,范围是[0,1)
    mask = (torch.rand(X.shape) > dropout).float()
    return mask * X / (1.0 - dropout)
```

当然，PyTorch自身也提供了名为`torch.nn.Dropout(dropout)`的dropout层模块，只需要加入`torch.nn.Sequential`中即可。

## 前向传播、反向传播、计算图

### 前向传播

*前向传播*（forward propagation）：按顺序（从输入层到输出层）计算和存储神经网络中每层的结果。

以单隐藏层、隐藏层无偏置项、带权重衰减机制的的多层感知机为例，说明前向传播的全过程。

假设输入为$x_{1\times d}$，则中间变量：
$$
z_{1\times h}=x_{1\times d}W_{d\times h}^{(1)}
$$
其中$W^{(1)}$是隐藏层的权重参数。中间变量需要通过激活函数，生成隐藏层输出：
$$
h_{1\times h} = \sigma(z_{1\times h})
$$
隐藏层输出需要根据输出层权重，生成模型的输出：
$$
o_{1\times q}=h_{1\times h}W_{h\times q}^{(2)}
$$
假设对应样本$x_{1\times d}$的标签为$y$，损失函数为$l$，则可以计算单个样本损失：
$$
L=l(o,y)
$$
L2正则化项为（$||W||_F$表示将矩阵$W$展平为向量，又称*Frobenius范数*）：
$$
s=\dfrac{\lambda}{2} \left(||W^{(1)}||_F^2+||W^{(2)}||_F^2\right)
$$
最终，模型在样本$x$上的正则化损失为：
$$
J=L+s
$$
$J$在前向传播和反向传播中又称*目标函数*（objective function）。

整个前向传播过程对应如下计算图：

![[Pasted image 20240901135519.png]]

### 反向传播

*反向传播*（back propagation）：计算神经网络参数梯度的方法。

梯度计算的核心原则是*求导的链式法则*：
$$
\dfrac{\partial J}{\partial W^{(1)}}= \dfrac{\partial J}{\partial L}\cdot \dfrac{\partial L}{\partial W^{(1)}} + \dfrac{\partial J}{\partial s}\cdot \dfrac{\partial s}{\partial W^{(1)}}
$$
右侧的这些偏导数也可以根据链式法则和求导法则一步步推出。

### 神经网络训练

在训练神经网络时，前向传播和反向传播*相互依赖*。 对于前向传播，我们沿着依赖的方向遍历计算图并计算其路径上的所有变量。 然后将这些用于反向传播，其中计算顺序与计算图的相反。

因此，在训练神经网络时，在初始化模型参数后， 我们交替使用前向传播和反向传播，利用反向传播给出的梯度来更新模型参数。 注意，反向传播重复利用前向传播中存储的中间值，以避免重复计算。 带来的影响之一是我们需要保留中间值，直到反向传播完成。 这也是训练比单纯的预测需要更多的内存（显存）的原因之一。 此外，这些中间值的大小与网络层的数量和批量的大小大致成正比。 因此，使用更大的批量来训练更深层次的网络更容易导致内存不足（out of memory）错误。

## 数值稳定性、模型初始化

为什么要重视模型的初始化：不谨慎的初始化可能造成梯度消失或梯度爆炸问题。

### 梯度消失、梯度爆炸

假设模型为$L$层的多层感知机，输入为$\mathbf{x}$，输出为$\mathbf{o}$，每一层可以写作函数$f_l$，则输出和输入的关系可以写作迭代函数的方式：
$$
\mathbf{h}^{(l)} = f_l (\mathbf{h}^{(l-1)}) \Rightarrow \mathbf{o} = f_L \circ \ldots \circ f_1(\mathbf{x}).
$$
其中，$\mathbf{o}$关于任意一组参数$W^{(l)}$的梯度为：
$$
\begin{split}
\partial_{\mathbf{W}^{(l)}} \mathbf{o} &= \underbrace{\partial_{\mathbf{h}^{(L-1)}} \mathbf{h}^{(L)}}_{ \mathbf{M}^{(L)} \stackrel{\mathrm{def}}{=}} \cdot \ldots \cdot \underbrace{\partial_{\mathbf{h}^{(l)}} \mathbf{h}^{(l+1)}}_{ \mathbf{M}^{(l+1)} \stackrel{\mathrm{def}}{=}} \cdot\underbrace{\partial_{\mathbf{W}^{(l)}} \mathbf{h}^{(l)}}_{ \mathbf{v}^{(l)} \stackrel{\mathrm{def}}{=}} \\
&= M^{(L)} \cdot M^{(L-1)} \cdot \ldots \cdot M^{(l+1)} \cdot \mathbf{v}^{(l)}
\end{split}
$$
其中，$\mathbf{v}^{(l)}$为第$l$层的输出。这种梯度之间的直接相乘可能引发一些问题：
- 如果各层梯度>1，则梯度间相乘会导致总梯度过大，即*梯度爆炸问题*，这种情形会破坏模型的稳定收敛；
- 如果各层梯度<1，则梯度间相乘会导致总梯度过小，即*梯度消失问题*，这种情形会导致参数更新过小，每次更新时几乎不移动，从而导致模型无法学习。

*梯度消失*（gradient vanishing）：

对于MLP隐藏层，有：
$$
\begin{split}
h_{k\times 1} &\leftarrow W_{k\times d}\cdot x_{d\times 1} \\
o_{k\times 1} &\leftarrow \sigma(h_{k\times 1}) \\
W_{k\times d} &\leftarrow W_{k\times d}-\lambda\cdot \dfrac{\partial L(W_{k\times d})}{\partial W_{k\times d}}
\end{split}
$$
考虑$\sigma\equiv\text{sigmoid}$，则输出$o\in (0,1)^{k\times 1}$，当$h$的取值过大时，$\partial o/\partial h\rightarrow 0$，因此：
$$
\dfrac{\partial o}{\partial x}=\dfrac{\partial o}{\partial h}\cdot \dfrac{\partial h}{\partial x}=\dfrac{\partial o}{\partial h}\cdot W\rightarrow 0
$$
此时$o$几乎不会随着$x$的改变而改变，因此计算得到的$W$的梯度极小，模型几乎无法学习。

另外，某些激活函数也会引入梯度消失问题，如Sigmoid函数：

```python
%matplotlib inline
import torch
from d2l import torch as d2l

x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)
y = torch.sigmoid(x)
y.backward(torch.ones_like(x))

d2l.plot(x.detach().numpy(), [y.detach().numpy(), x.grad.numpy()],
         legend=['sigmoid', 'gradient'], figsize=(4.5, 2.5))
```

![](https://zh-v2.d2l.ai/_images/output_numerical-stability-and-init_e60514_6_0.svg)

可见$|x|$增大时，Sigmoid函数的梯度是趋于0的，这便人为造成了损失函数的梯度过小。相反，ReLU或pReLU就不会存在这个问题。

*梯度爆炸*（gradient exploding）：模型中每个隐藏层的权值矩阵相乘，可能造成模型输出的梯度极大，从而导致模型对输入数据的变化过度敏感，进而导致模型不能稳定收敛。

### 参数初始化

正确的参数初始化方式可以解决（或减轻）梯度爆炸或梯度消失问题。

*默认初始化*：PyTorch对不同网络层的初始化方式不同。
- 线性层（`nn.Linear`）、卷积层（`nn.Conv2d`）、循环层（`nn.LSTM`、`nn.GRU`等）的权重使用均匀分布或正态分布，偏置初始为0；
- 嵌入层采用均匀分布；
- 批量归一化层将权重初始为1、偏置初始为0；
- Dropout层不需要初始化。

*Xavier初始化*：该初始化方法认为，网络层输出的方差应当与输入方差保持一致，这样模型输出就不会归于0。

假设全连接层的输入$x_j\sim N(0,\gamma^2)$，权重$w_{ij}\sim N(0,\sigma^2)$，$1\le i\le m,1\le j\le n$，所有变量相互独立。输出为：
$$
o_i=\sum_{j=1}^n w_{ij}x_j
$$
则输出的期望满足：
$$
E(o_i)=\sum_{j=1}^n E(w_{ij})E(x_j)=0
$$
输出的方差满足：
$$
\begin{split}
D(o_i)&=E(o_i^2)-(E(o_i))^2 \\
&=\sum_{j=1}^n E(w_{ij}^2 x_j^2)-0 \\
&= \sum_{j=1}^n E(w_{ij}^2) E(x_j^2) \\
&= n\sigma^2 \gamma^2
\end{split}
$$
可见输出$o_i\sim N(0,n\sigma^2\gamma^2)$。当$n\sigma^2=1$时，输出的方差与输入方差一致。

类似地，如果输出$o_i\sim N(0,\gamma^2)$，反向传播过程中如果需要保持参数梯度稳定，则需要保证$m\sigma^2=1$，但很显然$n\sigma^2=1$和$m\sigma^2=1$不可同时满足。

Xavier初始化要求权重方差$\sigma^2$满足：
$$
\dfrac{1}{2}(n+m)\sigma^2=1\Rightarrow \sigma^2=\dfrac{2}{n+m}
$$
在Xavier初始化中，权重一般从正态分布$N(0,2/(n+m))$或均匀分布$U(-\sigma',\sigma')$中选取，其中：
$$
\sigma'=\sqrt{\dfrac{6}{n+m}}
$$

## 环境和分布偏移

~~我能说我愣是没看懂d2l吗~~

[blog](https://blog.csdn.net/qq_42658739/article/details/136383614)

*分布偏移*（distribution shift）：模型在训练和测试数据集之间的数据分布不匹配的情况。

### 分布偏移的类型

*协变量偏移*（covariate shift）：*输入特征的分布*在训练和测试阶段发生了变化，但条件分布 
$P(y|x)$（给定特征$x$的标签分布）保持不变。

例如：训练天气预报模型时，输入数据介于20至30度，实际预测时输入介于10至20度，但预测模型是不变的。

*标签偏移*（label shift）：指的是*输出标签的分布*发生了变化，但条件分布$P(x|y)$（给定标签$y$的输入特征分布）不变。

例如：在某个地区训练的疾病分类模型，模型训练数据中某种疾病的发病率较高，但在新地区，发病率下降了。这种情况下，标签的分布改变了。

*概念偏移*（concept shift）：$P(y|x)$发生了变化，即*输入和输出的关系*发生了变化。

例如：某金融市场预测模型的训练数据可能基于某种经济规则，但该规则随着时间推移发生了变化，导致过去的输入-输出关系不再适用。

还有一种由数据收集过程的偏差导致的*采样偏移*（sampling bias），即训练数据和实际数据、测试数据不一致，不再赘述。

### 纠正分布偏移

部分情形下，分布偏移不需要手动纠正。但仍有一些情况下，需要借助特定的策略纠正分布偏移，使模型按照预期工作。

*经验风险*（empirical risk）：模型$f(x)$在训练数据集上的平均损失，又称*经验损失*。训练的过程便是最小化经验风险的过程：
$$
\min_{f} \dfrac{1}{n} \sum_{i=1}^n l(f(x_i),y_i)
$$
- 结构风险（structural risk）：经验风险+L2正则化项。

*实际风险*（真实风险、期望风险，true risk）：在整个数据集上的平均损失。
$$
E_{p(x,y)}(l(f(x),y))=\iint l(f(x),y)\cdot p(x,y) dxdy
$$

分布偏移的纠正本质是使经验风险与实际风险尽量接近。

#### 协变量偏移纠正

假设对于训练数据$(x_i,y_i)$，需要评估$P(y|x)$，但$x_i$是从某些原分布$q(x)$而非目标分布$p(x)$得到的。

由于此情形下，条件分布不变，故$p(y|x)=q(y|x)$。如果$q(x)$不幸是错误的，就需要通过等式纠正经验风险：
$$
\begin{aligned}
\iint l(f(\mathbf{x}), y) p(y \mid \mathbf{x})p(\mathbf{x}) \;d\mathbf{x}dy =
\iint l(f(\mathbf{x}), y) q(y \mid \mathbf{x})q(\mathbf{x})\frac{p(\mathbf{x})}{q(\mathbf{x})} \;d\mathbf{x}dy.
\end{aligned}
$$
对于每个测试数据$(x_i,y_i)$，将其权重$\beta_i$定义为其在正确分布、错误分布中的概率之比：
$$
\beta_i\overset{def}= \dfrac{p(x_i)}{q(x_i)}
$$
修正后的经验风险为：
$$
\min_f \dfrac{1}{n}\sum_{i=1}^n \beta_i\cdot l(f(x_i),y_i)
$$
但现实应用中，比值是难以计算的，需要估计。$p(x)$可以访问测试集，而$q(x)$需要自行生成或访问测试集。

d2l介绍了通过对数几率回归（logistic regression）评估这个比值的方法，它创建一个分类器用于分开从$p(x)$和从$q(x)$抽取的数据，输出$z=1$表示数据来自$p(x)$，输出$z=-1$表示数据来自$q(x)$。因此：
$$
P(z=1\mid x)= \dfrac{p(x)}{p(x)+q(x)}\Rightarrow \dfrac{P(z=1\mid x)}{P(z=-1\mid x)}=\dfrac{p(x)}{q(x)}
$$
对于对数几率回归，设参数化函数为$h(x)$，类别为$1,-1$，则：
$$
P(z=1\mid x)=\dfrac{1}{1+\exp (-h(x))}
$$
因此，整个偏移纠正分为两步：第一步是区分来自$p(x)$和$q(x)$的数据，第二步是加权。

完整步骤：设训练集为$(x_i,y_i)$，测试集为$\{u_j\}$，$1\le i\le n$，$1\le j\le m$。训练集来自某个源分布，测试集来自目标分布。
- 首先生成二元分类训练集：$\{(x_1,-1),\ldots,(x_n,-1),(u_1,1),\ldots,(u_m,1)\}$。
- 用对数几率回归训练二元分类器，得到函数$h$。
- 使用$\beta_i=\exp(h(x_i))$，或更好的$\beta_i=\min(\exp(h(x_i)),c)$对数据进行加权。
- 使用权重$\beta_i$进行训练，最小化经验风险。

#### 标签偏移纠正

我不敢说我看懂了d2l的讲述，所以还是删了原来的内容：[site](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/environment.html#id14)

*通过统计方法进行修正*：

首先，估计测试集中的标签分布：将测试集应用于现有模型，根据模型预测结果和实际结果获得混淆矩阵。再根据测试集上的混淆矩阵和先验分布，估计测试集中的标签分布：
$$
\hat{q}(y)=\sum_{x} \hat{p}(y|x) p(x)
$$
其中：$\hat{p}$是模型训练得到的后验概率，$p$是测试集的样本分布。

其次，根据观察到的标签分布，使用最大似然估计进行修正，防止过拟合。假设测试集标签分布为$q(y)$，训练集标签分布为$p(y)$。通过极大似然估计法来优化估计测试集中每个标签的比例。

*通过模型进行修正*：

一种思路是通过对损失函数进行加权，调整模型对不同标签的关注：
- 计算权重$w(y)=q(y)/p(y)$，即测试集中某个标签的分布与训练集分布的比率。
- 在损失函数中，将权重分别施加给每个训练样本。

另一种思路是重采样，通过重新采样修正标签分布。

#### 概念偏移纠正

一般难于通过原则性的方式解决。通用方法是，优先用新的数据更新模型参数，如果无效再重新训练模型。

## 案例：房价预测

房价预测数据集包含了约3000套房产的80个属性值和最终售价。

首先下载并加载数据集：

```python
import hashlib
import os
import tarfile
import zipfile
import requests

#@save
DATA_HUB = dict()
DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'

# 下载对应名称的数据集，返回下载到的本地路径
def download(name, cache_dir=os.path.join('..', 'data')):  #@save
    """下载一个DATA_HUB中的文件，返回本地文件名"""
    assert name in DATA_HUB, f"{name} 不存在于 {DATA_HUB}"
    url, sha1_hash = DATA_HUB[name]
    os.makedirs(cache_dir, exist_ok=True)
    fname = os.path.join(cache_dir, url.split('/')[-1])
    if os.path.exists(fname):
        sha1 = hashlib.sha1()
        with open(fname, 'rb') as f:
            while True:
                data = f.read(1048576)
                if not data:
                    break
                sha1.update(data)
        if sha1.hexdigest() == sha1_hash:
            return fname  # 命中缓存
    print(f'正在从{url}下载{fname}...')
    r = requests.get(url, stream=True, verify=True)
    with open(fname, 'wb') as f:
        f.write(r.content)
    return fname

def download_extract(name, folder=None):  #@save
    """下载并解压zip/tar文件"""
    fname = download(name)
    base_dir = os.path.dirname(fname)
    data_dir, ext = os.path.splitext(fname)
    if ext == '.zip':
        fp = zipfile.ZipFile(fname, 'r')
    elif ext in ('.tar', '.gz'):
        fp = tarfile.open(fname, 'r')
    else:
        assert False, '只有zip/tar文件可以被解压缩'
    fp.extractall(base_dir)
    return os.path.join(base_dir, folder) if folder else data_dir

def download_all():  #@save
    """下载DATA_HUB中的所有文件"""
    for name in DATA_HUB:
        download(name)

%matplotlib inline
import numpy as np
import pandas as pd
import torch
from torch import nn
from d2l import torch as d2l

DATA_HUB['kaggle_house_train'] = (  #@save
    DATA_URL + 'kaggle_house_pred_train.csv',
    '585e9cc93e70b39160e7921475f9bcd7d31219ce')

DATA_HUB['kaggle_house_test'] = (  #@save
    DATA_URL + 'kaggle_house_pred_test.csv',
    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')

train_data = pd.read_csv(download('kaggle_house_train'))
test_data = pd.read_csv(download('kaggle_house_test'))
```