
参考资料：
- [Prompting Guide](https://www.promptingguide.ai/zh)

## 模型设置

- token多样性：
	- `temperature`：参数越小，结果越确定，反之越多样化
	- `top_p`：与temperature类似，越小表示选择越确定
	- 区别：tokens中只有包含`top_p`概率质量的才会被考虑用于响应
	- 一般调一个超参就可以
- 响应长度控制：
	- `max_length`：输出最大长度。防止LLM生成冗长文本
	- `stop_sequence`：停止序列，防止LLM继续生成token
- 重复token控制：
	- `freq_penalty`：对下一个生成token的惩罚，与token出现的次数成比例。抑制*停用词*（最常出现词元）的过度出现
	- `pres_penalty`：对重复token的惩罚，但每个重复token的惩罚相同。抑制响应中重复词元的类别数
	- 单次调一个参数就可以

以Ollama的Modelfile为例：

```dockerfile
FROM ./deepseek-r1-distill-qwen-1.5b

PARAMETER stop <|eot|>
PARAMETER top_p 0.9
PARAMETER temperature 1.0
```

## 提示词设计

提示词常见格式：
- Q/A格式：`Q: xxx; A: xxx; Q: xxx; A: xxx; Q: yyy; A:`。最后一个Q是你想要问的问题，最后一个A留白，让LLM补充
- 以问号结束的一个问题
- 一条祈使句表示指令

*要素*：
- 指令：你想让LLM干什么
- 上下文：与指令相关的问题背景、上下文信息
- 输入数据
- 输出提示：引导LLM如何输出

要素示例：第一行为指令和输出提示，第二行为输入和上下文。

```
请将文本分为中性、否定或肯定
文本：我觉得食物还可以。
情绪：
```

设计提示的通用技巧：
- 明确指令类型（写入、分类、翻译、总结、排序等）
- 具体明确你希望模型执行的指令和任务。提示越具描述性，结果越好
- 更好的提示应当是非常具体、简洁并且切中要点的
- 避免说不要做什么，而应该说要做什么

### 提示词示例

文本概括：

```
Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body’s immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.

Explain the above in one sentence:
```

信息提取：

```
Author-contribution statements and acknowledgements in research papers should state clearly and specifically whether, and to what extent, the authors used AI technologies such as ChatGPT in the preparation of their manuscript and analysis. They should also indicate which LLMs were used. This will alert editors and reviewers to scrutinize manuscripts more carefully for potential biases, inaccuracies and improper source crediting. Likewise, scientific journals should be transparent about their use of LLMs, for example when selecting submitted manuscripts.

Mention the large language model based product mentioned in the paragraph above:
```

问答：

```
Answer the question based on the context below. Keep the answer short and concise. Respond "Unsure about answer" if not sure about the answer.

Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.

Question: What was OKT3 originally sourced from?

Answer:
```

文本分类：

```
Classify the text into neutral, negative or positive. 

Text: I think the vacation is okay.
Sentiment: neutral

Text: I think the food was okay. 
Sentiment:
```

对话：

```
The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.

Human: Hello, who are you?
AI: Greeting! I am an AI research assistant. How can I help you today?

Human: Can you tell me about the creation of blackholes?
AI:
```

代码生成：

```
"""
Table departments, columns = [DepartmentId, DepartmentName]
Table students, columns = [DepartmentId, StudentId, StudentName]
Create a MySQL query for all students in the Computer Science Department
"""
```

推理：

```
The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. 
Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even. 
```

## 提示技术

### 零样本提示（zero-shot）

提示词中不包含任何样本。

零样本提示需要一些技术手段支持：
- 指令调整：在通过指令描述的数据集上微调模型
- RLHF：来自人类反馈的强化学习手段

### 少样本提示（few-shot）

随着任务复杂度提升，零样本prompt可能无法得到预期结果，需要添加少量示例样本，使LLM尽量理解任务并返回正确的结果。

对于最先进的模型，1-shot对于一些日常任务已经足够。一些更困难的任务可能需要3-shot、5-shot甚至是10-shot。

*few-shot的限制*：在处理一些复杂任务尤其是推理任务时，它不能真正理解任务的要义，有可能生成错误甚至不相关的答案。
- 突破此类限制的手段：微调LLM，思维链（chain of thought, CoT）提示

### 链式思考（CoT）提示

*使用部分具有足够规模或推理功能的模型时*，在提示样本内增加得到答案的推理过程，可以使LLM更好地理解任务要义，从而能够生成正确结果。

![](https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcot.1933d9fe.png&w=1920&q=75)

例如当提供如下输入时：

```
Q: 这组数中的奇数加起来是偶数：4、8、9、15、12、2、1。
A：将所有奇数相加（9、15、1）得到25。答案为False。
Q: 这组数中的奇数加起来是偶数：15、32、5、13、82、7、1。
A：
```

稍微出名的LLM都会返回如下输出：

```
将所有奇数相加（15、5、13、7、1）得到41。答案为False。
```

而一些训练欠佳或无法推理的LLM，仍可能返回错误结果。

*零样本CoT*：在输入提示中显式要求模型启用逐步思考，如：“让我们逐步思考：xxx”
- 在没有或者很少有样本可供参考时，这个prompt很有用

*自动思维链*（automatic chain-of-thought, Auto-CoT）：
- 背景：人工prompt可能导致次优解，零样本CoT可能在生成链内出错
- 目的：对具有多样性的问题进行采样，并生成推理链来构建演示
- 两个阶段：
	- **问题聚类**：将给定问题划分为几个聚类
	- **演示抽样**：从每类中选择一个具有代表性的问题，并使用带有*简单启发式*的Zero-Shot-CoT生成其推理链
		- 简单启发式方法可以是问题长度（e.g. 60 tok's）和推理步骤数（e.g. 5 steps）

![[Pasted image 20250225180851.png]]

thesis: [2210.03493](https://arxiv.org/abs/2210.03493)

code: [amazon-science/auto-cot](https://github.com/amazon-science/auto-cot)

### 自我一致性

*自我一致性*（self consistency）：
- 旨在“替换CoT提示中使用的天真贪婪解码方法”
- 想法是通过少样本 CoT 采样多个不同的推理路径，并使用生成结果选择最一致的答案。这有助于提高 CoT 提示在涉及算术和常识推理的任务中的性能

例如，这个问题有可能得到35岁之类的荒谬回答：

```
当我6岁时，我的妹妹是我的一半年龄。现在我70岁了，我的妹妹多大？
```

但可以使用自我一致性，通过少样本CoT采用不同推理路径，使LLM利用这些样本选择最合适的答案：

```
Q：林中有15棵树。林业工人今天将在林中种树。完成后，将有21棵树。林业工人今天种了多少棵树？
A：我们从15棵树开始。后来我们有21棵树。差异必须是他们种树的数量。因此，他们必须种了21-15 = 6棵树。答案是6。

Q：停车场有3辆汽车，又来了2辆汽车，停车场有多少辆汽车？
A：停车场已经有3辆汽车。又来了2辆。现在有3 + 2 = 5辆汽车。答案是5。

Q：Leah有32块巧克力，她的姐姐有42块。如果他们吃了35块，他们总共还剩多少块？
A：Leah有32块巧克力，Leah的姐姐有42块。这意味着最初有32 + 42 = 74块巧克力。已经吃了35块。因此，他们总共还剩74-35 = 39块巧克力。答案是39。

Q：Jason有20个棒棒糖。他给Denny一些棒棒糖。现在Jason只有12个棒棒糖。Jason给Denny多少棒棒糖？
A：Jason有20个棒棒糖。因为他现在只有12个，所以他必须把剩下的给Denny。他给Denny的棒棒糖数量必须是20-12 = 8个棒棒糖。答案是8。

Q：Shawn有五个玩具。圣诞节，他从他的父母那里得到了两个玩具。他现在有多少个玩具？
A：他有5个玩具。他从妈妈那里得到了2个，所以在那之后他有5 + 2 = 7个玩具。然后他从爸爸那里得到了2个，所以总共他有7 + 2 = 9个玩具。答案是9。

Q：服务器房间里有9台计算机。从周一到周四，每天都会安装5台计算机。现在服务器房间里有多少台计算机？
A：从周一到周四有4天。每天都添加了5台计算机。这意味着总共添加了4 * 5 =
20台计算机。一开始有9台计算机，所以现在有9 + 20 = 29台计算机。答案是29。

Q：Michael有58个高尔夫球。星期二，他丢失了23个高尔夫球。星期三，他又丢失了2个。星期三结束时他还剩多少个高尔夫球？
A：Michael最初有58个球。星期二他丢失了23个，所以在那之后他有58-23 = 35个球。星期三他又丢失了2个，所以现在他有35-2 = 33个球。答案是33。

Q：Olivia有23美元。她用每个3美元的价格买了五个百吉饼。她还剩多少钱？
A：她用每个3美元的价格买了5个百吉饼。这意味着她花了15美元。她还剩8美元。

Q：当我6岁时，我的妹妹是我的一半年龄。现在我70岁了，我的妹妹多大？
A：
```

大部分的输出都是正确的：

```
当叙述者6岁时，他的妹妹是他年龄的一半，也就是3岁。现在叙述者70岁了，他的妹妹应该是70-3 = 67岁。答案是67。
```

### 生成知识提示