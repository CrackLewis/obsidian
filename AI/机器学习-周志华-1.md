
## ch01-绪论

计算机科学：输入+模型->输出

机器学习：输入+输出->模型

模型：从数据中学习得到的结果
- 模式：模型的一个局部

基本术语：
- *数据集*（data set）：数据记录集合
- *样本*（sample）、*实例*（instance）：数据记录的别称
- *属性*（attribute）、*特征*（feature）：数据记录的某方面表现、性质的反映
	- *属性值*（attribute value）：这一方面的数值
	- *属性空间*（attribute space）、*样本空间*（sample space）：属性张成的空间
- *特征向量*（feature vector）：数据记录的数学表示
- *维度*（dimensionality）：特征向量的维度数
- *学习*（learning）、*训练*（training）：从数据学得模型的过程
- *训练数据*（training data）、*训练样本*（training sample）
- *训练集*（training set）
- *假设*（hypothesis）：学得的模型对应了关于数据的某种潜在规律
	- *真实*（ground-truth）：这种潜在规律自身
	- *学习器*（learner）：模型别称
- *预测*（prediction）
- *标记*（label）、*样例*（example）
- *标记空间*（label space）
- *测试*（testing）：
	- *测试样本*（testing sample）
	- *测试集*（test set）
- 机器学习任务：
	- *分类*（classification）
		- *二分类*（binary classification）：*正类*（positive class）、*反类*（negative class）
		- *多分类*（multi-class classification）
	- *回归*（regression）
	- *聚类*（clustering）：将训练样本分为若干相近的组
		- *簇*（cluster）：每个划分形成的组
- *有监督学习*（supervised learning）：提供标记信息的学习过程
- *无监督学习*（unsupervised learning）：不提供标记信息的学习过程
- *泛化*（generalization）：学得模型适用于新样本的能力
- *分布*（distribution）：样本在样本空间中的分散情况
	- *独立同分布*（independent and identically distributed, i.i.d.）

归纳（induction）：从特殊到一般的泛化过程
- 从具体事实归结出一般规律
- 从样例中学习即是归纳过程
- 广义归纳学习样例特征，狭义归纳学习概念

演绎（deduction）：从一般到特殊的特化过程
- 从一般规律出发推演出具体状况

*归纳偏好*（inductive bias）：如果模型无法确定新样本属于哪个分类，则它必根据自己在学习过程中对某种类型假设的偏好进行归纳。
- 理解：学习算法自身在假设空间中学习成的“价值观”
- 例：模型倾向于认为各种属性均相近的西瓜，成熟程度也相似
- *“没有免费的午餐”定理*（no-free-lunch theorem, NFL）：
	- 各个学习算法在训练集外的期望性能相同，都约等于乱猜
	- 如果一个学习算法$L_a$在训练集上表现比$L_b$好，则必存在另一些数据集使得$L_b$的表现更好
	- 前提：所有问题的出现机会相等，但现实不是这样
	- 启示：谈论哪个学习算法更好时，*必须带上具体问题*

发展历程：
- 1950s-70s: 推理期：
	- Logic Theorist, General Problem Solving, etc.
	- 连接主义学习、感知机、符号主义学习
- 1970s-80s: 知识期
	- 逻辑推理不能实现AI，需要依赖知识
	- 专家系统、知识工程
- 1980s-90s: 机器学习形成
	- Michalski分类：*样例中学习*（广义归纳学习）、问题求解和规划中学习、观察和发现学习、指令中学习
	- 样例学习分支：
		- 符号主义学习：决策树（信息熵最小化）、基于逻辑学习（归纳逻辑程序设计）等
		- 连接主义学习：神经网络、BP算法等
- 1990s-: 统计学习
	- 支持向量机、核方法等
- 2000s-: 连接学习重新兴起
	- 背景：数据量增大，计算能力变强
	- 深度学习：多层神经网络

应用现状：
- 计算机：多媒体/图形学/通信/软工/体系结构/芯片设计
- 交叉学科：生信/CV/etc.
- 数据挖掘：since 90s

## ch02-模型评估与选择

### 2.1-经验误差与过拟合

错误率（error rate）：分类错误的样本数占总样本比例
- 精度（accuracy）：分类正确的样本数占总样本比例
	- 精度=1-错误率
- 误差（error）：实际预测与真实输出的差异
	- 训练误差（training error）、经验误差（empirical error）：在训练集上的误差
	- 泛化误差（generalization error）：在训练集外的误差
- 过拟合（overfitting）：训练样本学得“太好”了，以至于对训练集外的样本表现较差
- 欠拟合（underfitting）：连训练样本都没学好

学习目标：*降低泛化误差*，而非刻意降低训练误差

### 2.2-评估方法

测试集（testing set）：数据集的一个用于评估模型学习效果的子集
- 测试误差（testing error）：模型在测试集上的误差

*训练集-测试集划分手段*：数据集$D$分为训练集$S$，测试集$T$。
- 留出法（hold-out）：$D=S\cup T,S\cap T=\varnothing$。设定$|S|/|T|=k$，一般取$2\sim4$之间。
- 交叉验证法（cross validation）：$D=\bigcup_{i=1}^n D_i$，且$\forall 1\le i,j\le n$，$D_i\cap D_j=\varnothing$。每轮取$T=D_i,S=D-D_i$，总共$n$轮。
- 自助法（bootstrapping）：
	- 每轮随机挑选$x\in D$，将其拷贝入可重集合$S$，总共进行$|D|$轮
	- 当$m$足够大时，任意$x\in D$不在$S$中的概率为$P(x\notin S)=\lim_{m\rightarrow +\infty}(1-1/m)^m=1/e\approx 0.368$ 。
	- 取$T=D-S$，则$T$大约包含36.8%的$D$样本，属合理范围

手段比较：
- 留出法：简单，但偶然性大
- 交叉验证法：偶然性小，但时间成本大
- 自助法：在难于划分数据集时有用，但改变了数据集分布，会引入估计偏差

*调参*（parameter tuning）*与最终模型*：
- 绝大部分模型都有参数，需要调节
- 调参vs算法选择：调参需要试验大量参数，且对模型性能有决定性影响
- 验证集vs测试集：
	- 模型评估&选择时，需要预留一些数据用于验证模型性能，这部分数据称为*验证集*（validation set）
	- 测试集则是确定模型后测试训练效果的数据集

### 2.3-性能度量

模型性能=模型泛化能力

*均方误差*（mean squared error, MSE）：对于模型$f$和数据集$D=\{(x_i,y_i)|1\le i\le m\}$：
$$
E(f;D)=\dfrac{1}{m}\sum_{i=1}^m (f(x_i)-y_i)^2
$$
或更一般地：对于$f$和$D$，设样本$x$在$D$中概率密度$p(\cdot)$，标签为$y$，则：
$$
E(f;D)=\int_{x\sim D} (f(x)-y)^2 p(x)dx
$$

*错误率*（error rate）：设$\mathbb{I}(\cdot)$为单元函数，将布尔表达式映射为$0/1$：
$$
E(f;D)=\int_{x\sim D} \mathbb{I}(f(x)\neq y)\cdot p(x)dx
$$
*精度*（accuracy rate）：
$$
\text{acc}(f;D)=\int_{x\sim D} \mathbb{I}(f(x)= y)\cdot p(x)dx=1-E(f;D)
$$

查准率、查全率、F1：
- 背景：错误率/精度信息不全，可能需要研究误判类型（实际为正预测为反，实际为反预测为正）
- 分类结果：
	- TP/TN：预测、实际均为真/假，true positive/negative
	- FP/FN：预测为真/假，实际为假/真，false positive/negative
- *查准率*（precision）：
	- 概念：TP占所有预测为真样本的比率
	- 定义：$P=\dfrac{TP}{TP+FP}$
- *查全率*（recall）：
	- 概念：TP占所有实际为真样本的比率
	- 定义：$R=\dfrac{TP}{TP+FN}$
- 查准率vs查全率：
	- 两者矛盾，一者偏高则另一者常常偏低：提升查准率需要更保守地预测，但保守预测可能增加FN，从而降低查全率，反之亦然
	- *P-R图*：对所有样本按查全率升序排列，根据当前的实际查准率绘制曲线，形成查准率-查全率曲线
		- 意义：更凸出（或平衡点更高）的曲线表示更优秀的模型
		- 平衡点（break-event point，BEP）：$y=x$与曲线的交点
- F1度量：
	- 意义：查准率和查全率的加权调和平均
	- 一般形式：设查全率对查准率重要度为$\beta$，则$F_\beta=\dfrac{(1+\beta^2)PR}{\beta^2P+R}$。
		- $\beta=1$：*标准F1度量*
		- $\beta>1$表示查全率$R$影响更大，$\beta<1$表示查准率$P$影响更大
- 处理多组混淆矩阵：
	- 计算每组的$(P_i,R_i)$
	- 宏度量：
		- 计算宏查准率和宏查全率：$\text{M-}P=\sum_{i=1}^n P_i/n$，$\text{M-}R=\sum_{i=1}^n R_i/n$。
		- 计算宏F1：$\text{M-}F1=\dfrac{2\times \text{M-}P\times \text{M-}R}{\text{M-}P+\text{M-}R}$。
	- 微度量：
		- 计算每组的TP/FP/TN/FN，并取均值
		- 计算微查准率和微查全率：$\text{m-P}=\dfrac{\overline{TP}}{\overline{TP}+\overline{FP}}$，$\text{m-}R=\dfrac{\overline{TP}}{\overline{TP}+\overline{FN}}$。
		- 计算微F1：$\text{m-}F1=\dfrac{2\times \text{m-}P\times \text{m-}R}{\text{m-}P+\text{m-}R}$。

P-R图示例：

![[Pasted image 20241004172046.png]]

ROC与AUC：
- 背景：在分类任务中，特别是当数据集类别不平衡时，单纯依赖准确率或P-R可能会造成误导
	- 例如：数据集中95%为反例，5%为正例，即使模型总是预测为反例也有95%准确率，但这毫无意义
- 相关指标：
	- 真正例率（true positive rate，TPR）：$TPR=\dfrac{TP}{TP+FN}$。
	- 假正例率（false positive rate，FPR）：$FPR=\dfrac{FP}{TN+FP}$。
- *受试者工作特征*（ROC, receiver operating characteristic）曲线：横轴为样本的假正例率，纵轴为真正例率
	- 绘制过程：假设对每个样本会输出真实率$p_i\in [0,1]$。
		- 取阈值$P\in [0,1]$，对$p_i<P$的样本预测为反例，其余预测为正例，并计算其TPR和FPR。
		- 取足够多的阈值，计算出的TPR/FPR绘制成一条从$(0,0)$到$(1,1)$的曲线
- 曲线下面积（AUC, area under the curve）：ROC曲线下面积，又称AUC，可用于衡量一个学习器的效果
	- 计算方式：设阈值TPR-FPR为$\{(x_i,y_i)\}$，则$\text{AUC}=\dfrac{1}{2}\displaystyle\sum_{i=1}^{m-1} (x_{i+1}-x_i)\cdot (y_i+y_{i+1})$。
	- 衡量方式：AUC>0.5说明有一定学习效果，AUC=0.5说明和瞎猜没区别，AUC<0.5说明还不如瞎猜

![[Pasted image 20241005194225.png]]

代价敏感错误率、代价曲线：
- 背景：两类错误的代价有时不同：如果实际正常被误诊为患病，影响有限；实际患病被误诊为正常，则可能产生严重后果。因此两类错误可能需要指定*非均等代价*（unequal cost）
- 非均等代价：设置$k$分类代价矩阵$\{cost_{ij}\}$（$i,j\in \{0,1,\ldots,k-1\}$），对所有的$i\neq j$设置$cost_{ij}>0$，表示真实为$i$预测为$j$的代价。
- 代价敏感错误率（cost-sensitive error rate）：设判为反例的样例集为$D^-$，判为正例的样例集为$D^+$，则：
 $$E(f;D;cost)=\dfrac{1}{m}\left(\sum_{x_i\in D^+} \mathbb{I}(f(x_i)\neq y_i)\cdot cost_{01}+\sum_{x_i\in D^-} \mathbb{I}(f(x_i)\neq y_i)\cdot cost_{10}\right)$$
- *代价曲线*（cost curve）：反映学习器的真实损失情况，横轴为正例概率代价，纵轴为归一化代价
	- 正例概率代价：设样本正例概率为$p$：
$$
P(+)cost=\dfrac{p\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}
$$
	- 归一化代价：设$\text{FPR}$为假正例率，$\text{FNR}$为假反例率
$$
cost_{norm}=\dfrac{\text{FNR}\times p\times cost_{01}+\text{FPR}\times (1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}
$$
	- 绘制：
		- 对ROC曲线上任意一点$(\text{TPR},\text{FPR})$，计算$\text{FNR}=1-\text{TPR}$
		- 对每个点，在代价平面上绘制一条$(0,\text{FPR})\rightarrow (1,\text{FNR})$的线段
		- 所有线段与横轴围成一个小区域，如下图

![[Pasted image 20241006105635.png]]

### 2.4-比较检验

回顾：
- 评估方法：测试集、验证集
- 性能度量：
	- 错误率与精度、均方误差
	- 查准率、查全率、P-R图、F1度量
	- FPR、FNR、ROC-AUC
	- 代价敏感错误率、代价曲线

why：
- 希望比较的是泛化性能，与测试集上的性能未必一致
- 测试集的选择会影响结果
- 学习算法的随机性

*统计假设检验*（hypothesis test）：在测试集上观察到A优于B，那么A的泛化性能在统计意义上有多大把握优于B

本节默认性能度量为错误率，记作$\epsilon$

#### 假设检验

假设（hypothesis）：对泛化错误率$\epsilon$分布的某种猜想，如$\epsilon=\epsilon_0$
- 现实中不知道$\epsilon$，只知道测试集错误率$\hat{\epsilon}$
- $|\epsilon-\hat{\epsilon}|$较小的可能性大，较大的可能性小

对规模为$m$的测试集，出错的样本数为$\hat{\epsilon}\times m$，测试集错误率为$\hat{\epsilon}$的概率：
$$
P(\hat{\epsilon};\epsilon)=\text{C}_m^{\hat{\epsilon}\times m} \epsilon^{\hat{\epsilon}\times m}(1-\epsilon)^{m-\hat{\epsilon}\times m}
$$
由$\dfrac{\partial P(\hat{\epsilon};\epsilon)}{\partial \epsilon}=0$知：$P(\cdot)$在$\epsilon=\hat{\epsilon}$时最大。

*二项检验*（binomial test）：

考虑诸如$\epsilon\le \epsilon_0$这种假设，在$1-\alpha$的概率内所能观察到的最大错误率：
$$
\overline{\epsilon}=\max \epsilon\quad \text{s.t.} \quad \sum_{i=\epsilon_0\times m+1}^m\left(\begin{matrix}m\\i\end{matrix}\right)\epsilon^i (1-\epsilon)^{m-i} <\alpha
$$
$1-\alpha$称为结论（$\epsilon\le \epsilon_0$）的*置信度*（confidence）。若$\hat{\epsilon}<\overline{\epsilon}$，则可以认为：在$\alpha$的显著度下，假设$\epsilon\le \epsilon_0$不能被拒绝，即能以$1-\alpha$的置信度认为$\epsilon\le \epsilon_0$；否则假设可被拒绝，即在$\alpha$的显著度下可认为$\epsilon>\epsilon_0$。

![[Pasted image 20241006144641.png]]

对于多次验证得到的$\hat{\epsilon}_i$（$1\le i\le k$），考虑使用*t-检验*（t-test）：
- 平均错误率：$\mu=\dfrac{1}{k}\displaystyle\sum_{i=1}^k \hat{\epsilon}_i$
- 方差：$\sigma^2=\dfrac{1}{k-1}\displaystyle\sum_{i=1}^k (\hat{\epsilon}_i-\mu)^2$
- 此时，随机变量$\tau_t=\dfrac{\sqrt{k}(\mu-\epsilon_0)}{\sigma}\sim t(k-1)$。

对假设$\mu=\epsilon_0$和显著度$\alpha$，可计算出当测试错误率均值为$\epsilon_0$时，在$1-\alpha$概率内能观测到的最大错误率，即临界值。这里考虑双边假设：
- 若平均错误率$\mu$与$\epsilon_0$之差$|\mu-\epsilon_0|\in [t_{-\alpha/2},t_{\alpha/2}]$，则不能拒绝假设$\mu=\epsilon_0$，即可以认为$\epsilon=\epsilon_0$，置信度为$1-\alpha$
- 否则可拒绝该假设，即在该显著度下认为$\epsilon\neq \epsilon_0$

![[Pasted image 20241006170543.png]]

#### 交叉验证t检验

假如同样的数据集分别用于测试学习器A和B，经过$k$折交叉验证后得到的测试错误率分别为$\epsilon_i^A$和$\epsilon_i^B$（$1\le i\le k$），相同的$i$对应同一折的测试集。

*成对t检验*（paired t-tests）：

模型A/B的测试错误率差值$\Delta_i=\epsilon_i^A-\epsilon_i^B$。

若模型性能相同，则$\sum_{i=1}^k \Delta_i =0$。

考虑对“模型A与模型B性能相同”的假设作t检验，计算出差值的均值$\mu$和方差$\sigma$，再计算出正则化变量：
$$
\tau_t=\left|\dfrac{\sqrt{k}\mu}{\sigma}\right|\sim t(k-1)
$$
若：
- $\tau_t<t_{\alpha/2}$，则假设不能被拒绝，即有$1-\alpha$的置信度认为A/B性能无显著差异
- $\tau_t\ge t_{\alpha/2}$：在显著度为$\alpha$时，A/B性能有较明显的差异

#### McNemar检验

用于分析和比较两个相关或配对的二分类变量，如是或否、相关和无关等。常使用2x2列联表作为检验工具。

对二分类问题，模型A和B的表现可能不同，设分类正确为0、错误为1，并计算列联矩阵$e_{ij}$（$i,j\in \{0,1\}$），表示模型A/B分类结果分别为$i,j$的样本个数。例如$e_{01}$表示A分类正确而B分类错误的样本数。

若假设A、B性能一致，则有$e_{01}=e_{10}$。此时：
$$
|e_{01}-e_{10}|\sim N(1,e_{01}+e_{10})
$$
基于此计算McNemar检验的统计量：
$$
\tau_{\chi^2}=\dfrac{(|e_{01}-e_{10}|-1)^2}{e_{01}+e_{10}}\sim \chi^2(1)
$$
给定显著度$\alpha$：
- 当$\tau_{\chi^2}<\chi_\alpha^2$时，假设不能被拒绝，认为模型A、B的性能无明显差异
- 否则拒绝假设，认为A、B性能有显著差距，且平均错误率$\hat{\epsilon}$更小的模型性能更优

#### Friedman检验、Nemenyi后续检验

交叉验证t检验、McNemar检验：只能在一个数据集上比较两个算法

*Friedman检验*：

假定用$N$个数据集比较$k$个算法：

首先需要预处理，计算出各个算法在所有数据集中的平均序值：
- 第一步是用数据集测试每个算法，得到结果。
- 第二步是对每个数据集，将各个算法的性能排序，并根据性能好坏赋予不同序值，最好的赋序值1，次好的为2，最差的为$k$。并列的取平均，确保所有算法的序值总和为$\dfrac{k^2+k}{2}$。
- 第三步是对每个算法，求其在所有数据集中序值的平均值，记作$r_i$（$1\le i\le k$）。

例如：$N=4,k=3$：

![[Pasted image 20241006234905.png]]

当$k,N$足够大时，$r_i$服从$N(\mu,\sigma^2)$，其中：
$$
\mu=\dfrac{k+1}{2},\sigma^2=\dfrac{k^2-1}{12}
$$
卡方统计量：
$$
\tau_{\chi^2}=\dfrac{k-1}{k}\cdot \dfrac{N}{\sigma^2}\sum_{i=1}^k \left(r_i-\mu\right)^2\sim \chi^2(k-1)
$$
或者进一步使用F分布统计量：
$$
\tau_F = \dfrac{(N-1)\tau_{\chi^2}}{N(k-1)-\tau_{\chi^2}}\sim F(k-1,(k-1)(N-1))
$$
这些统计量也可以作为验证学习算法性能是否相同的依据。

如果算法被验证为具有显著不同的性能，则需进行*后续检验*（post-hoc test），例如*Nemenyi后续检验*。后续检验用于确认哪些算法是相同的，哪些是不同的。

计算平均序值差别的临界值域：
$$
CD=q_\alpha \sqrt{\dfrac{k(k+1)}{6N}}
$$
查书中的$q_a$表，计算出$CD$值。将$CD$值与任意两个算法的平均序值之差$|r_i-r_j|$作对比：
- 若$|r_i-r_j|<CD$，说明这两个算法性能是相同的。
- 否则说明这两个算法性能显著不同。

### 2.5-偏差与方差

*偏差-方差分解*（bias-variance decomposition）：对学习算法的期望泛化错误率进行拆解，分析出哪些错误是由数据分布引起的（方差），哪些是由数据集与现实数据偏差造成的（噪声），哪些是模型泛化能力造成的（偏差）。

设测试样本为$x$，$y$为$x$的真实标记，$y_D$为$x$在数据集$D$中的标记，$f$为学习模型，$f(x;D)$为训练集$D$上学得模型$f$在$x$上的预测输出。

学习算法的期望预测为：
$$
\overline{f}(x)=E_D[f(x;D)]
$$
使用不同训练集$D$产生的方差：
$$
var(x)=E_D\left[\left(f(x;D)-\overline{f}(x)\right)^2\right]
$$
*噪声*（noise）表示数据集标签与样本真实标签的偏差：
$$
\varepsilon^2 = E_D\left[(y_D-y)^2\right]
$$
*偏差*（bias）表示模型预测输出与真实标签的偏差：
$$
bias^2(x)=\left(\overline{f}(x)-y\right)^2
$$
为简化问题，假设噪声期望为0，即：
$$
E_D[y_D-y]=0
$$
则算法的期望泛化误差可作如下分解：
$$
\begin{split}
E(f;D)=& E_D\left[(f(x;D)-y_D)^2\right] \\
=& E_D\left[(f(x;D)-\overline{f}(x)+\overline{f}(x)-y_D)^2\right] \\
=& E_D\left[(f(x;D)-\overline{f}(x))^2\right]+E_D\left[(\overline{f}(x)-y_D)^2\right] \\
&+E_D\left[2(f(x;D)-\overline{f}(x))(\overline{f}(x)-y_D)\right] \\
=& E_D\left[(f(x;D)-\overline{f}(x))^2\right]+E_D\left[(\overline{f}(x)-y_D)^2\right] \\
=& E_D\left[(f(x;D)-\overline{f}(x))^2\right]+E_D\left[(\overline{f}(x)-y+y-y_D)^2\right] \\
=& E_D\left[(f(x;D)-\overline{f}(x))^2\right]+E_D\left[(\overline{f}(x)-y)^2\right]+E_D\left[(y-y_D)^2\right] \\
&+ 2E_D\left[(\overline{f}(x)-y)(y-y_D)\right] \\
=& E_D\left[(f(x;D)-\overline{f}(x))^2\right]+(\overline{f}(x)-y)^2+E_D\left[(y_D-y)^2\right] \\
=& bias^2(x)+var(x)+\varepsilon^2
\end{split}
$$

说明算法的期望泛化误差为偏差、方差和噪声的总和：
- 偏差：衡量算法拟合能力，表示算法的期望预测与真实结果的偏离度
- 方差：刻画数据扰动影响，表示相同规模训练集变动导致的性能变化
- 噪声：刻画学习问题难度，表示任何算法在当前学习任务中的误差下界

*偏差-方差窘境*（bias-variance dilemma）：

偏差和方差一般存在冲突。如果模型欠拟合，则偏差大，此时模型受数据扰动较小，方差也较小。如果模型过拟合，则偏差小，但模型对数据过于敏感，受数据扰动影响大，方差也偏大。

![[Pasted image 20241007113610.png]]

## ch03-线性模型

### 3.1-基本形式

对$d$个属性描述的示例$x=(x_1,x_2,\cdots,x_d)$，其中$x_i$为示例的第$i$个属性值，*线性模型*（linear model）试图学得一个通过属性值线性组合来预测的函数：
$$
f(x)=w_1x_1+w_2x_2+\cdots +w_dx_d+b
$$
向量形式为：
$$
f(x)=w^Tx+b
$$
其中：$w=(w_1,w_2,\cdots,w_d)$为模型的权重，$b$为模型的偏移。

- 优点：简单、易于建模、解释性强
- 缺点：过于简单了，几乎所有模型都比它复杂

### 3.2-线性回归

如果属性值为离散值，则需要进行独热码编码，将其转换为若干个连续属性。

*多元线性回归*（multivariate linear regression）试图学得一组$(w,b)$，使得对于任意数据$(x_i,y_i)$（$1\le i\le m$）：
$$
f(x_i)=w^T x_i + b\quad s.t.\quad f(x_i)\simeq y_i
$$

设数据集为$X_{m\times (d+1)}$，每行一个样本，总计$m$个样本。对于第$i$行，有：
$$
X_{i}=(x_{i1},x_{i2},\cdots,x_{id},1)=(x_i;1)
$$
对应的标签向量$y=(y_1;y_2;\cdots;y_m)$。

为讨论方便，组合$\hat{w}=(w;b)$，故有$f(x_i)=w^Tx+b=\hat{w}^T(x_i;1)$。

考虑所有样例，最佳的$\hat{w}$满足：
$$
E_{\hat{w}}=\hat{w}^*=\underset{\hat{w}}{\arg\min}\ (y-X\hat{w})^T (y-X\hat{w})
$$
这等价于求一个超平面$w^Tx+b-y=0$，使得所有样例点到平面的欧氏距离平方和最小。

对$\hat{w}$求导得：
$$
\dfrac{\partial E_{\hat{w}}}{\partial \hat{w}} = 2 X^T (X\hat{w}-y)
$$
解$\partial E_{\hat{w}}/\partial \hat{w}=0$，这等价于线性方程组$X^TX\hat{w}=X^Ty$。

若$X^TX$满秩，则方程组必有唯一解：
$$
\hat{w}^*=(X^TX)^{-1} X^Ty
$$
如果$X^TX$不满秩（变量数甚至多于样例数），此时可能有多个$\hat{w}$符合要求，此时依赖算法偏好进行选择，例如：引入正则化项。

*对数线性回归*（log-linear regression）：
$$
\ln y=w^Tx+b
$$

更一般地，*广义线性模型*（generalized linear model）在线性模型基础上引入单调可微函数$g(\cdot)$，使得：
$$
y=g^{-1}(w^Tx+b)
$$
其中：$g(\cdot)$称*联系函数*（link function）。

### 3.3-对数几率回归

线性回归模型不仅适用于回归任务，还适用于分类任务。

朴素线性模型输出为$\mathbb{R}$上的实值，有可能需要利用广义模型中的联系函数进行转换。

*单位阶跃函数*（unit-step function）：根据实值正负将其转换为0/1形式：
$$
y=\left\{\begin{matrix}
0, & z<0;\\
0.5, & z=0;\\
1, & z>0.
\end{matrix}\right.
$$
可惜的是，它不满足单调可微的性质。

*对数几率函数*（logistic function）：
$$
y=\dfrac{1}{1+e^{-z}}
$$
它满足单调可微的性质，因此可作为$g(\cdot)$组成线性模型：
$$
y=\dfrac{1}{1+e^{-(w^Tx+b)}} \Leftrightarrow \ln \dfrac{y}{1-y}=w^Tx+b
$$
其中：
- $y/(1-y)$表示正例可能性与反例可能性之比，又称*几率*（odds）
- $\ln\dfrac{y}{1-y}$称为*对数几率*（log odds, logit）

*对数几率回归*（logistic regression）：用线性回归模型的预测结果来逼近真实标记的对数几率。注意，对数几率回归*实际上是分类模型*。

为确定模型中的$w,b$，可以重写$y$为$p(y=1|x)$，$1-y$为$p(y=0|x)$：
$$
\ln \dfrac{y}{1-y}=\ln \dfrac{p(y=1|x)}{p(y=0|x)}=w^Tx+b
$$
可以推出：
$$
p(y=1|x)=\dfrac{e^{w^Tx+b}}{1+e^{w^Tx+b}},p(y=0|x)=\dfrac{1}{1+e^{w^Tx+b}}
$$
通过*极大似然法*（maximum likelihood method）估计$w,b$：令每个样本属于其真实标记的概率越大越好，则有：
$$
L(w,b)=\sum_{i=1}^m \ln p(y_i\mid x_i; w,b)
$$
为方便讨论，令$\beta=(w;b)$，$\hat{x}=(x;1)$，则$w^Tx+b=\beta^T \hat{x}$。再令$p_1(\hat{x};\beta)=p(y=1\mid \hat{x};\beta)$，$p_0(\hat{x};\beta)=p(y=0\mid \hat{x};\beta)=1-p_1(\hat{x};\beta)$，则似然项可重写为：
$$
p(y_i\mid x_i;w,b)=y_i p_1(\hat{x}_i;\beta)+(1-y_i)p_0(\hat{x}_i;\beta)
$$
代入得：
$$
L(\beta)=\sum_{i=1}^m \left(-y_i\beta^T \hat{x}_i+\ln\left(1+e^{\beta^T \hat{x}_i}\right)\right)
$$
函数$L(\beta)$是一个关于$\beta$的高阶可导连续凸函数，根据梯度下降法或牛顿法得：
$$
\beta^* =\underset{\beta}{\arg\min}\ L(\beta)
$$
以牛顿法为例，对$\beta$进行迭代下降，若干轮后$\beta$将收敛：
$$
\beta^{t+1}=\beta^{t}-\left(\dfrac{\partial^2 L(\beta)}{\partial\beta\ \partial \beta^T}\right)^{-1} \dfrac{\partial L(\beta)}{\partial \beta}
$$
其中：
$$
\begin{split}
\dfrac{\partial L(\beta)}{\partial \beta}&= -\sum_{i=1}^m \hat{x}_i (y_i-p_1(\hat{x}_i;\beta)) \\
\dfrac{\partial^2 L(\beta)}{\partial \beta\ \partial \beta^T}&= 
\sum_{i=1}^m \hat{x}_i \hat{x}_i^T p_1(\hat{x}_i;\beta)(1-p_1(\hat{x}_i;\beta))
\end{split}
$$

### 3.4-线性判别分析

*线性判别分析*（linear discriminant analysis，LDA）：经典线性学习方法。将样本投影至一条直线，使同类样本投影尽可能近，异类样本投影尽可能远。

给定数据集$D=\{(x_i,y_i)\}_{i=1}^m$，$y_i\in\{0,1\}$。当标签为$i$时，令：
- $X_i$为对应标签的样本集
- $\mu_i$为样本集$X_i$的均值向量
- $\Sigma_i$为样本集$X_i$的协方差矩阵：$\Sigma_i=\sum_{x\in X_i} (x-\mu_i)(x-\mu_i)^T$

LDA的目标：
- 最大化均值向量投影的距离：$||w_T\mu_0-w^T\mu_1||_2^2$
- 最小化样本集内投影的协方差：$w^T\Sigma_0 w+w^T\Sigma_1 w$

将最大化目标作为分子，最小化目标作为分母，即形成最大化目标$J$：
$$
J=\dfrac{||w_T\mu_0-w^T\mu_1||_2^2}{w^T\Sigma_0 w+w^T\Sigma_1 w}=\dfrac{w^T(\mu_0-\mu_1)(\mu_0-\mu_1)^Tw}{w^T(\Sigma_0+\Sigma_1) w}
$$

*类内散度矩阵*（within-class scatter matrix）：
$$
S_w=\Sigma_0+\Sigma_1
$$
*类间散度矩阵*（between-class scatter matrix）：
$$
S_b=(\mu_0-\mu_1)(\mu_0-\mu_1)^T
$$
因此$J$可改写为：
$$
J=\dfrac{w^TS_b w}{w^TS_w w}
$$
这是一个求多元函数最值问题。令$w^T S_w w=1$，并引入系数：
$$
S_b w=\lambda S_w w
$$
解得：
$$
w=S_w^{-1} (\mu_0-\mu_1)
$$
求解的过程依赖拉格朗日乘数法，比较繁琐，过程在P61-P62。

LDA也可应用于$N$分类任务。这涉及到引入全局散度矩阵，求出合适的投影矩阵$W_{d\times (N-1)}$，使得均值输出向量$y=W^T \mu_i$间的距离最大化，同时类别内样本投影的协方差最小。

### 3.5-多分类学习

$N$分类学习基本思路：拆分为若干个二分类学习任务，对每个任务训练一个分类器，由各分类器的分类结果汇总为$N$分类结果。

问题拆分策略：
- 一对一：对每两个类别组织一个学习任务，总计$N(N-1)/2$组。分类结果为被划入最多次的类别
- 一对其余：每次将一个类别作为正例，其他类别作为反例，总计$N$组。分类结果选择判为正例、预测置信度最大的类别
- 多对多：最一般的形式
	- *纠错输出码*（error correcting output codes，ECOC）：一种多对多划分技术，有一定容错能力。编码阶段，利用编码矩阵划分类别，对$N$个类别进行$M$次划分，总计生成$M$个学习任务，每个类别根据其正反类持有一个长度为$M$的编码。解码阶段，$M$个分类器分别对测试样本预测，预测结果组成一个编码，计算该编码与各类别编码的码距，码距最小者即为所属类别。详情见P64-P65。
	- DAG拆分法等

也有直接求解多分类的，涉及到SVM相关

### 3.6-类别不平衡问题

背景：分类问题下，不同类别的样本数可能不同，甚至差异悬殊。这种情形称为*类别不平衡*（class-imbalance）。

二分类问题中，采用过根据输出值是否大于0.5判断正反例的方法，这种方法实际上假定了正反例概率相等。实际问题中，设正例、反例个数分别为$m^+,m^-$，则对$y$进行*再缩放*（rescaling）：
$$
\dfrac{y'}{1-y'}=\dfrac{y}{1-y}\times\dfrac{m^+}{m^-}
$$
再判断$y'$是否大于0.5即可。

数据集未必是真实样本总体的无偏采样（问火车上的人是否都买了票）。解决方法（假设反例多于正例）：
- *欠采样*（undersampling）：去除一些多余反例。开销较低。
	- 不能随机丢弃反例
	- EasyEnsemble算法：反例划分为子集
- *过采样*（oversampling）：多取一些正例。开销较大。
	- 不能对初始正例重采样，否则过拟合
	- SMOTE算法：对正例进行插值
- *阈值移动*（threshold-moving）：不变动数据集，但运用再缩放技巧。

*代价敏感学习*（cost-sensitive learning）：运用再缩放技巧

## ch04-决策树

### 4.1-基本流程

*决策树*（decision tree）是一种机器学习方法，执行由粗入细的决策过程。

决策树生成：遵循分治思想
- 特殊情形：标签相同、所有属性值相同、子集为空

![[Pasted image 20241008205143.png]]

### 4.2-划分选择

决策树学习的关键一步是：如何选择最优划分属性
- 目标：分支节点所包含的样本尽量属于同一类别，即*纯度*（purity）尽可能高

3指标：信息增益、增益率、Gini指数

#### 信息增益

*信息熵*（information entropy）：度量样本集合纯度。熵值越低，纯度越高。设样本集$D$中第$k$类样本占总样本率为$p_k$（$1\le k\le |\Upsilon|$），则信息熵：
$$
\text{Ent}(D)=-\sum_{k=1}^{|\Upsilon|}  p_k\log_2 p_k
$$
假设属性$a$有$V$个可行取值$\{a_i\}$（$1\le i\le V$），若使用$a$划分$D$，则按值划分为$V$个子集，每个子集记作$D_i$（$1\le i\le V$）。划分子集一般会降低总的信息熵，降低的差值称为*信息增益*（information gain），可用作决策树选择的参考：
$$
\text{Gain}(D,a)=\text{Ent}(D)-\sum_{i=1}^V \dfrac{|D_i|}{|D|}\text{Ent}(D_i)
$$
最佳属性满足：
$$
a^* = \underset{a\in A}{\arg\max}\ \text{Gain}(D,a)
$$

#### 增益率

单纯的信息增益面临一个问题：假如每个样本的某个属性$a'$值都不同（类似于ID），那么以该属性为依据划分将使信息熵归0，取得最大信息增益。但这么做没意义。

为每个属性$a$定义*固有值*（intrinstic value），表示属性取值的复杂程度，取值越复杂将给信息增益带来越大的惩罚：
$$
\text{IV}(a)=-\sum_{i=1}^V \dfrac{|D_i|}{|D|}\log_2 \dfrac{|D_i|}{|D|}
$$
依据属性$a$划分的*增益率*（gain ratio）定义为增益值和固有值的比值：
$$
\text{Gain\_ratio}(D,a)=\dfrac{\text{Gain}(D,a)}{\text{IV}(a)}
$$
与增益值相反，增益率准则一般偏好于可取值数目较少的属性。

#### 基尼指数

*基尼指数*（Gini index）是另一种选取划分属性的度量。

*基尼值*（Gini value）反映从数据集$D$中随机抽取两个样本，它们的类别不同的概率：
$$
\text{Gini}(D)=1-\sum_{k=1}^{|\Upsilon|} p_k^2
$$
基尼值越小，数据集纯度越高。

*基尼指数*：设$D_i$为按照属性$a$划分得到的子集。
$$
\text{Gini\_index}(D,a)=\sum_{i=1}^V \dfrac{|D_i|}{|D|} \text{Gini}(D_i)
$$

### 4.3-剪枝处理

决策树过拟合：学的太好，把数据集自身特点当成一般性质。

*预剪枝*（prepruning）：划分结点前估计，如果划分不能显著提升决策树的泛化性能，则停止划分，将结点标记为叶结点。

划分准则：
- 划分是否比不划分显著提升了分类精度
- 划分是否会引起错判，从而拉低精度

优点：减少开销，模型简单

缺点：过于贪心，有可能造成泛化性能的损失（事实上短期的精度下降有可能使得后期精度上升）

*后剪枝*（postpruning）：先划分出决策树，再自底向上考察，将部分子树替换为叶结点，以期提升决策树的泛化效率。

优点：欠拟合风险小，泛化性能更好

缺点：开销更大

### 4.4-连续与缺失值

#### 连续值处理

*连续属性离散化*：

假设连续属性$a$在数据集$D$上有$n$个取值$a_i$（$\forall 1\le i< n$，$a_i\le a_{i+1}$）。考察区间中点集合$T_a$，在其中选取划分点：
$$
T_a=\left\{\dfrac{a_i+a_{i+1}}{2}\mid 1\le i\le n-1 \right\}
$$
设划分点为$t$，将$D$中大于$t$的子集记作$D_t^+$，小于$t$的子集记作$D_t^-$。则基于划分点$t$划分属性$a$的信息增益：
$$
\begin{split}
\text{Gain}(D,a)&=\underset{t\in T_a}{\max} \text{Gain}(D,a,t) \\
&=\underset{t\in T_a}{\max} \text{Ent}(D)-\sum_{\lambda\in \{-,+\}} \dfrac{|D_t^\lambda|}{|D|} \text{Ent}(D_t^\lambda)
\end{split}
$$
通过二分法可以在集合$T_a$中选择出信息增益最大的$t$值。

#### 缺失值处理

问题：
- 属性值缺失时如何进行划分属性选择
- 给定划分属性，若样本在该属性的值缺失，如何划分

假设对于数据集$D$和属性$a$，属性值非缺失的子集为$\tilde{D}$。假定$a$属性有$V$个合法取值，按照取值划分为子集$\tilde{D}^v$（$1\le v\le V$）；按照类别划分为子集$\tilde{D}_k$（$1\le k\le |{\Upsilon}|$）。显然，$\tilde{D}=\bigcup_{k=1}^{|\Upsilon|} \tilde{D}_k$，$\tilde{D}=\bigcup_{v=1}^{V} \tilde{D}^v$。

假设每个样本$x\in D$具有权重$w_x$，并定义：
- 无缺失值样本比例：$\rho=\dfrac{\sum_{x\in \tilde{D}} w_x}{\sum_{x\in D} w_x}$。
- 无缺失值样本中第$k$类样本比例：$\tilde{p}_k=\dfrac{\sum_{x\in \tilde{D}_k} w_x}{\sum_{x\in D} w_x}$。
- 无缺失值样本中在属性$a$上取值为$a^v$的样本比例：$\tilde{r}_v=\dfrac{\sum_{x\in \tilde{D}^v} w_x}{\sum_{x\in D} w_x}$。

信息增益的计算式：
$$
\begin{split}
\text{Gain}(D,a)&=\rho\times \text{Gain}(\tilde{D},a) \\
&=\rho\times \left(\text{Ent}(\tilde{D})-\sum_{v=1}^V \tilde{r}_v \text{Ent}(\tilde{D}^v)\right)
\end{split}
$$
其中：
$$
\text{Ent}(\tilde{D})=-\sum_{k=1}^{|\Upsilon|} \tilde{p}_k \log_2 \tilde{p}_k
$$

### 4.5-多变量决策树

朴素决策树：决策边界平行于坐标轴

*多变量决策树*（multivariate decision tree）：每个非叶节点不是只按一个属性划分，而是通过线性分类器等评估多个属性的综合表现，进行子集划分。例如：满足$a+2b\ge 4$划分为A类，否则划分为B类。

## ch05-神经网络

*神经网络*（neural network）是由具有适应性的简单单元组成的广泛并行互连的网络。

### 5.1-神经元模型

*神经元*（neuron）：神经网络的简单单元。

McCulloch-Pitts神经元模型：接收$n$个输入信号，输入信号通过带权重的*连接*（connection）进行传递，总输入值与*阈值*（threshold）比较，最后通过*激活函数*（activation function）处理产生输出：
$$
y=f\left(\sum_{i=1}^n w_ix_i-\theta\right)
$$

激活函数：阶跃函数、Sigmoid、tanh、ReLU等

### 5.2-感知机与多层网络

*感知机*（perceptron）：两层神经元组成的简单神经网络。
- 输入层：$n$个输入神经元